import streamlit as st
import json
import random
import os
import difflib
import re
import tempfile
import numpy as np
import time
import speech_recognition as sr
from gtts import gTTS
import ssl
import pandas as pd
import uuid
import zipfile
import io

# [æ ¸å¿ƒ] ä½¿ç”¨ Google Generative AI
import google.generativeai as genai

# ==========================================
# 1. è¨­å®šé é¢ (å¿…é ˆæ˜¯ç¬¬ä¸€å€‹ Streamlit æŒ‡ä»¤)
# ==========================================
try:
    st.set_page_config(page_title="AI è‹±æ–‡æ•™ç·´ Pro (çŸ¥è­˜çŸ­æ–‡ç‰ˆ)", layout="wide", page_icon="ğŸ“")
except:
    pass

# 2. å¿½ç•¥ SSL éŒ¯èª¤
ssl._create_default_https_context = ssl._create_unverified_context

# 3. å®‰å…¨åŒ¯å…¥é›¢ç·šå¥—ä»¶
HAS_OFFLINE_TTS = False
try:
    import pyttsx3
    HAS_OFFLINE_TTS = True
except ImportError:
    HAS_OFFLINE_TTS = False

try:
    import librosa
    HAS_LIBROSA = True
except ImportError:
    HAS_LIBROSA = False

# ==========================================
# 4. å…¨åŸŸå¸¸æ•¸å®šç¾©
# ==========================================
VOCAB_FILE = "vocab_book.json"
GRAMMAR_FILE = "grammar_stats.json"
STORY_FILE = "story_book.json" # Added STORY_FILE based on context, user snippet had it
KEY_FILE = "api_key.txt"

# ==========================================
# 5. æ‰€æœ‰å‡½æ•¸å®šç¾©
# ==========================================

def inject_custom_css():
    st.markdown("""
        <style>
        .stApp { background: linear-gradient(135deg, #fdfbf7 0%, #ebedee 100%) !important; font-family: 'Microsoft JhengHei', sans-serif; }
        .main .block-container h1, .main .block-container h2, .main .block-container h3, .main .block-container h4, .main .block-container p, .main .block-container div, .main .block-container span, .main .block-container label, .main .block-container li { color: #000000 !important; }
        [data-testid="stSidebar"] { background-color: #263238 !important; }
        [data-testid="stSidebar"] h1, [data-testid="stSidebar"] h2, [data-testid="stSidebar"] h3, [data-testid="stSidebar"] p, [data-testid="stSidebar"] span, [data-testid="stSidebar"] div, [data-testid="stSidebar"] label, [data-testid="stSidebar"] .stMarkdown { color: #ffffff !important; }
        [data-testid="stSidebar"] input { color: #000000 !important; }
        .reading-box { font-size: 26px !important; font-weight: bold; color: #2c3e50 !important; line-height: 1.6; padding: 20px; background-color: #ffffff !important; border-left: 8px solid #4285F4; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.15); margin-bottom: 20px; white-space: pre-wrap; font-family: 'Courier New', Courier, monospace; }
        .definition-card { background-color: #fff9c4 !important; border: 2px solid #fbc02d; color: #3e2723 !important; padding: 15px; border-radius: 12px; margin-top: 15px; font-size: 18px; }
        .mobile-hint-card { background-color: #e3f2fd !important; border-left: 5px solid #2196f3; padding: 10px; border-radius: 8px; margin-bottom: 10px; font-size: 16px; font-weight: 600; color: #0d47a1 !important; }
        .quiz-box { background-color: #ffffff !important; border: 2px solid #4caf50; padding: 25px; border-radius: 15px; margin-top: 10px; box-shadow: 0 4px 10px rgba(0,0,0,0.1); text-align: center;}
        .quiz-question { font-size: 24px; font-weight: bold; color: #1565c0 !important; margin-bottom: 20px; line-height: 1.6; }
        .hint-box { background-color: #ffebee !important; color: #c62828 !important; padding: 10px; border-radius: 5px; font-weight: bold; margin-top: 10px; border: 1px dashed #ef9a9a;}
        .leaderboard-box { background-color: #fff3e0 !important; padding: 10px; border-radius: 8px; border: 1px solid #ffcc80; margin-bottom: 15px; color: #e65100 !important; }
        .ai-feedback-box { background-color: #f1f8e9 !important; border-left: 5px solid #8bc34a; padding: 15px; border-radius: 10px; color: #33691e !important; margin-top: 20px;}
        .diff-box { background-color: #ffffff !important; border: 2px dashed #bdc3c7; padding: 15px; border-radius: 10px; font-size: 18px; color: #333333 !important; }
        .story-text-large { font-size: 28px !important; font-family: 'Georgia', serif; color: #1a237e; line-height: 1.6; padding: 15px; background-color: #e8eaf6; border-radius: 8px; margin-bottom: 20px; white-space: pre-wrap;}
        div.stButton > button { width: 100%; border-radius: 8px; height: 3em; font-weight: bold; }
        </style>
    """, unsafe_allow_html=True)

def transcribe_audio(audio_path):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            audio_data = r.record(source)
            return r.recognize_google(audio_data, language="en-US")
    except sr.UnknownValueError:
        return ""
    except sr.RequestError:
        return "API Error"
    except Exception:
        return ""

def load_vocab():
    if not os.path.exists(VOCAB_FILE): return []
    try:
        with open(VOCAB_FILE, "r", encoding="utf-8") as f: 
            data = json.load(f)
            for item in data:
                if "error_count" not in item: item["error_count"] = 0
                if "pronunciation_errors" not in item: item["pronunciation_errors"] = 0
            return data
    except: return []

def save_vocab_to_disk(vocab_list):
    with open(VOCAB_FILE, "w", encoding="utf-8") as f:
        json.dump(vocab_list, f, ensure_ascii=False, indent=4)

def load_stories():
    if not os.path.exists(STORY_FILE): return []
    try:
        with open(STORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except: return []

def save_story_to_disk(content, explanation=None):
    stories = load_stories()
    for s in stories:
        if s["content"] == content:
            if explanation and not s.get("explanation"):
                s["explanation"] = explanation
                with open(STORY_FILE, "w", encoding="utf-8") as f:
                    json.dump(stories, f, ensure_ascii=False, indent=4)
                return "UPDATED"
            return False
    
    title = content[:20] + "..." if len(content) > 20 else content
    new_story = {
        "id": str(uuid.uuid4()),
        "date": time.strftime("%Y-%m-%d %H:%M"),
        "title": title,
        "content": content,
        "explanation": explanation
    }
    stories.insert(0, new_story)
    with open(STORY_FILE, "w", encoding="utf-8") as f:
        json.dump(stories, f, ensure_ascii=False, indent=4)
    return True

def add_word_to_vocab(word, info):
    if not word or "æŸ¥è©¢å¤±æ•—" in info or "è«‹è¼¸å…¥ API Key" in info or "Exception" in info: return False
    vocab_list = load_vocab()
    for v in vocab_list:
        if v["word"].lower() == word.lower(): return False
    vocab_list.append({"word": word, "info": info, "error_count": 0, "pronunciation_errors": 0})
    save_vocab_to_disk(vocab_list)
    return True

def increment_error_count(target_word):
    vocab_list = load_vocab()
    updated = False
    for v in vocab_list:
        if v["word"] == target_word:
            if "error_count" not in v: v["error_count"] = 0
            v["error_count"] += 1
            updated = True
            break
    if updated:
        save_vocab_to_disk(vocab_list)

def increment_pronunciation_error(target_word):
    vocab_list = load_vocab()
    updated = False
    for v in vocab_list:
        if v["word"] == target_word:
            if "pronunciation_errors" not in v: v["pronunciation_errors"] = 0
            v["pronunciation_errors"] += 1
            updated = True
            break
    if updated:
        save_vocab_to_disk(vocab_list)

def restore_pronunciation_data(data_list):
    vocab_list = load_vocab()
    vocab_dict = {v['word']: v for v in vocab_list}
    count = 0
    for item in data_list:
        word = item.get('word')
        errors = item.get('pronunciation_errors', 0)
        if word:
            if word in vocab_dict:
                vocab_dict[word]['pronunciation_errors'] = errors
                count += 1
            else:
                new_item = {
                    "word": word,
                    "info": item.get('info', "å¾…æŸ¥è©¢: é‚„åŸè³‡æ–™"),
                    "error_count": item.get('error_count', 0),
                    "pronunciation_errors": errors
                }
                vocab_list.append(new_item)
                vocab_dict[word] = new_item
                count += 1
    save_vocab_to_disk(vocab_list)
    return count

def load_grammar_stats():
    if not os.path.exists(GRAMMAR_FILE): return {}
    try:
        with open(GRAMMAR_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except: return {}

def update_grammar_stats(topic, is_correct, question_text, user_answer, correct_answer, ai_feedback):
    stats = load_grammar_stats()
    if topic not in stats:
        stats[topic] = {"total": 0, "correct": 0, "errors": []}
    
    stats[topic]["total"] += 1
    if is_correct:
        stats[topic]["correct"] += 1
    else:
        new_error = {
            "time": time.strftime("%Y-%m-%d %H:%M"),
            "q": question_text,
            "user": user_answer,
            "ans": correct_answer,
            "feedback": ai_feedback
        }
        if "errors" not in stats[topic]: stats[topic]["errors"] = []
        stats[topic]["errors"].append(new_error)
        stats[topic]["errors"] = stats[topic]["errors"][-50:]
        
    with open(GRAMMAR_FILE, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=4)

def process_imported_text(text_content):
    words = re.findall(r'\b[a-zA-Z]+\b', text_content)
    valid_words = [w for w in words if len(w) >= 2]
    seen = set()
    unique_words = []
    for w in valid_words:
        w_lower = w.lower()
        if w_lower not in seen:
            seen.add(w_lower)
            unique_words.append(w)
    return unique_words

def count_syllables(word):
    word = word.lower()
    count = 0
    vowels = "aeiouy"
    if word[0] in vowels: count += 1
    for index in range(1, len(word)):
        if word[index] in vowels and word[index - 1] not in vowels:
            count += 1
    if word.endswith("e"): count -= 1
    if count == 0: count += 1
    return count

def generate_random_word_ai(api_key, model_name):
    if not api_key: return "API_KEY_MISSING"
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        
        if random.random() < 0.7:
            requirement = "ä¸€å€‹ã€å¤šéŸ³ç¯€ (2å€‹éŸ³ç¯€ä»¥ä¸Š)ã€çš„è‹±æ–‡å–®å­— (Multi-syllabic word)"
        else:
            requirement = "ä¸€å€‹ã€å–®éŸ³ç¯€ã€çš„è‹±æ–‡å–®å­— (Single-syllable word)"
            
        prompt = f"""
        è«‹éš¨æ©Ÿçµ¦æˆ‘ {requirement}ã€‚
        é›£åº¦ï¼šé©åˆè‹±èªå­¸ç¿’è€… (CEFR B1-B2)ã€‚
        è«‹åªå›å‚³ã€Œå–®å­—æœ¬èº«ã€ï¼Œä¸è¦æœ‰ä»»ä½•æ¨™é»ç¬¦è™Ÿæˆ–é¡å¤–æ–‡å­—ã€‚
        """
        responses = model.generate_content(prompt, stream=False)
        return responses.text.strip().replace(".", "").replace("\n", "")
    except Exception as e:
        return f"ERROR: {str(e)}"

def handle_ai_error(e, model_name):
    err_str = str(e)
    if "429" in err_str: return f"âš ï¸ {model_name} é¡åº¦å·²æ»¿ (429)ã€‚è«‹åˆ‡æ›æ¨¡å‹ã€‚"
    elif "404" in err_str: return f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹ {model_name} (404)ã€‚è«‹å˜—è©¦ä½¿ç”¨è‡ªå‹•åµæ¸¬çš„æ¨¡å‹ã€‚"
    else: return f"âŒ AI ç™¼ç”ŸéŒ¯èª¤: {err_str}"

# [ä¿®æ”¹] è©•åˆ†æ•™ç·´å‡½æ•¸ï¼šå„ªåŒ– Promptï¼Œè¦æ±‚æ­£é¢é¼“å‹µä½†ç²¾æº–ç³¾éŒ¯
def get_ai_coach_feedback(api_key, model_name, target_text, user_text, score, pitch_correlation):
    if not api_key: return "âš ï¸ è«‹åœ¨å´é‚Šæ¬„è¼¸å…¥ Google API Key"
    
    # æ ¹æ“šèªèª¿ç›¸é—œæ€§çµ¦å‡ºæç¤º
    intonation_hint = ""
    if pitch_correlation < -0.2:
        intonation_hint = "âš ï¸ èªèª¿è¶¨å‹¢èˆ‡åŸå¥ç›¸å (è©²ä¸Šæšå»ä¸‹é™ï¼Œæˆ–åä¹‹)ã€‚"
    elif pitch_correlation > 0.6:
        intonation_hint = "âœ… èªèª¿èµ·ä¼éå¸¸è‡ªç„¶ï¼Œè·ŸåŸå¥å¾ˆåƒã€‚"
    else:
        intonation_hint = "èªèª¿ç¨é¡¯å¹³æ·¡ï¼Œèµ·ä¼ä¸å¤ æ˜é¡¯ã€‚"

    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        prompt = f"""
        ä½ æ˜¯ä¸€ä½æº«æš–ã€æ­£å‘ä½†å°ˆæ¥­çš„è‹±æ–‡ç™¼éŸ³æ•™ç·´ã€‚
        
        ç›®æ¨™å¥å­ï¼š"{target_text}"
        å­¸ç”Ÿå”¸å‡ºï¼š"{user_text}"
        ç¶œåˆåˆ†æ•¸ï¼š{score:.0f} (æ»¿åˆ†100)
        èªèª¿åˆ†æï¼š{intonation_hint}
        
        è«‹ç”¨ç¹é«”ä¸­æ–‡çµ¦äºˆå›é¥‹ï¼Œè«‹éµå®ˆä»¥ä¸‹åŸå‰‡ï¼š
        1. **æ­£é¢é¼“å‹µ (Positive reinforcement)**ï¼šé–‹é ­è«‹å…ˆè‚¯å®šå­¸ç”Ÿçš„å˜—è©¦ï¼Œæ‰¾å‡ºäº®é»ï¼ˆä¾‹å¦‚èªé€Ÿã€æ¸…æ™°åº¦æˆ–åŠªåŠ›ï¼‰ã€‚
        2. **ç²¾æº–ç³¾éŒ¯ (Constructive correction)**ï¼š
           - å¦‚æœæœ‰ç™¼éŸ³éŒ¯èª¤çš„å­—ï¼Œè«‹æº«æŸ”åœ°æŒ‡å‡ºä¾†ã€‚
           - **é‡é»**ï¼šè‹¥èªèª¿åˆ†æé¡¯ç¤ºã€Œç›¸åã€æˆ–ã€Œå¹³æ·¡ã€ï¼Œè«‹æ˜ç¢ºæŒ‡å‡ºï¼ˆä¾‹å¦‚ï¼šã€Œé€™å¥çµå°¾æ˜¯ä¸Šæšçš„ï¼Œè©¦è‘—æŠŠéŸ³èª¿æ‹‰é«˜ä¸€é»ã€ï¼‰ï¼Œä¸è¦ç‚ºäº†æ­£é¢è€Œå¿½ç•¥éŒ¯èª¤ã€‚
        3. **çµå°¾æ‰“æ°£**ï¼šçµ¦ä¸€å¥é¼“å‹µçš„è©±ï¼Œè®“å­¸ç”Ÿæƒ³å†è©¦ä¸€æ¬¡ã€‚
        
        è«‹ä¿æŒå›é¥‹ç°¡æ½”æœ‰åŠ›ï¼Œä¸è¦é•·ç¯‡å¤§è«–ã€‚
        """
        responses = model.generate_content(prompt, stream=False)
        return responses.text
    except Exception as e:
        return handle_ai_error(e, model_name)

def get_ai_text_explanation(api_key, model_name, text):
    if not api_key: return "âš ï¸ è«‹å…ˆè¼¸å…¥ API Keyã€‚"
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        prompt = f"""
        ä½ æ˜¯ä¸€ä½æ•™å­¸ç¶“é©—è±å¯Œã€èªæ°£è¦ªåˆ‡å¹½é»˜çš„è‹±æ–‡è€å¸«ã€‚
        ä½ çš„å­¸ç”Ÿæ˜¯è‹±æ–‡åˆå­¸è€…ã€‚
        
        è«‹é‡å°ä»¥ä¸‹é€™ç¯‡è‹±æ–‡çŸ­æ–‡ï¼š
        "{text}"
        
        è«‹ä¾ç…§ä»¥ä¸‹é †åºé€²è¡Œæ•™å­¸ (è«‹ç”¨ç¹é«”ä¸­æ–‡)ï¼š
        
        ### 1. ğŸ“ å…¨æ–‡ç¿»è­¯ (Translation)
        - **è«‹å‹™å¿…æœ€å…ˆæä¾›**é€šé †è‡ªç„¶çš„ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼Œè®“å­¸ç”Ÿå…ˆçœ‹æ‡‚æ–‡ç« åœ¨èªªä»€éº¼ã€‚
        
        ### 2. ğŸ“– æ–‡ç« è„ˆçµ¡èˆ‡æ¶æ§‹ (Structure & Context)
        - ç°¡å–®èªªæ˜é€™ç¯‡æ–‡ç« çš„ä¸»é¡Œã€å ´æ™¯è¨­å®šï¼Œä»¥åŠæ•…äº‹ç™¼å±•çš„é‚è¼¯ (ä¾‹å¦‚ï¼šé–‹é ­ä»‹ç´¹äº†ä»€éº¼ï¼Œä¸­é–“ç™¼ç”Ÿäº†ä»€éº¼ï¼Œæœ€å¾Œçµæœå¦‚ä½•)ã€‚
        
        ### 3. ğŸ”‘ é‡é»å¥å‹åˆ†æ (Key Sentence Patterns)
        - æŒ‘é¸æ–‡ä¸­ 2-3 å€‹æœ€å¯¦ç”¨çš„ã€Œå¥å‹çµæ§‹ã€é€²è¡Œè§£èªª (ä¾‹å¦‚ï¼šIt is... to..., There is..., Subject + Verb + Object)ã€‚
        - èªªæ˜é€™å€‹å¥å‹çš„æ¶æ§‹ï¼Œä»¥åŠé€šå¸¸ç”¨åœ¨ä»€éº¼æƒ…æ³ã€‚
        
        ### 4. ğŸ“š æ–‡æ³•å°æ•™å®¤ (Grammar Points)
        - è§£ææ–‡ä¸­çš„æ™‚æ…‹ (Tense)ã€ä»‹ç³»è© (Prepositions) æˆ–å…¶ä»–æ–‡æ³•ç´°ç¯€ã€‚
        
        è«‹ä¿æŒæ’ç‰ˆæ¸…æ™°ï¼Œé©ç•¶ä½¿ç”¨ Emojiï¼Œè®“å­¸ç¿’éç¨‹æ„Ÿè¦ºè¼•é¬†æ„‰å¿«ã€‚
        """
        response = model.generate_content(prompt, stream=False)
        return response.text
    except Exception as e:
        return handle_ai_error(e, model_name)

def get_pronunciation_feedback(api_key, model_name, target_word, user_text):
    if not api_key: return "âš ï¸ ç„¡æ³•é€£ç·š AI"
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        prompt = f"""
        ä½ æ˜¯ä¸€ä½**éå¸¸åš´æ ¼**çš„è‹±æ–‡æ­£éŸ³è€å¸«ã€‚
        å­¸ç”Ÿæ­£åœ¨ç·´ç¿’å–®å­—ï¼š"{target_word}"
        èªéŸ³è¾¨è­˜çµæœç‚ºï¼š"{user_text}" (å¦‚æœçµæœèˆ‡ç›®æ¨™ä¸ç¬¦ï¼Œä»£è¡¨ç™¼éŸ³æœ‰èª¤)

        è«‹é€²è¡Œä»¥ä¸‹æ•™å­¸ï¼š
        1. **KKéŸ³æ¨™**ï¼šåˆ—å‡ºè©²å–®å­—çš„ KK éŸ³æ¨™ã€‚
        2. **éŸ³ç¯€æ‹†è§£**ï¼šå¦‚æœæ˜¯å¤šéŸ³ç¯€å–®å­—ï¼Œè«‹æ‹†è§£éŸ³ç¯€ (å¦‚ u-ni-ver-si-ty)ã€‚
        3. **é€å€‹éŸ³ç¯€è¬›è§£**ï¼šè«‹è©³ç´°èªªæ˜æ¯å€‹éŸ³ç¯€çš„ç™¼éŸ³é‡é» (æ¯éŸ³ã€é‡éŸ³ä½ç½®)ã€‚
        4. **éŒ¯èª¤åˆ†æ**ï¼šå¦‚æœå­¸ç”Ÿå”¸éŒ¯ (è¾¨è­˜çµæœä¸åŒ)ï¼Œè«‹åˆ†æå¯èƒ½ç™¼éŒ¯äº†å“ªå€‹éŸ³ã€‚
        
        è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
        """
        responses = model.generate_content(prompt, stream=False)
        return responses.text
    except Exception as e:
        return handle_ai_error(e, model_name)

def generate_pronunciation_report(api_key, model_name, error_list):
    if not api_key: return "âš ï¸ è«‹å…ˆè¼¸å…¥ API Keyã€‚"
    if not error_list: return "ç›®å‰æ²’æœ‰ç™¼éŸ³éŒ¯èª¤ç´€éŒ„ã€‚"
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä½èªè¨€æ²»ç™‚å¸«èˆ‡è‹±æ–‡æ­£éŸ³å°ˆå®¶ã€‚ä»¥ä¸‹æ˜¯å­¸ç”Ÿå¸¸å”¸éŒ¯çš„å–®å­—åˆ—è¡¨ (å«éŒ¯èª¤æ¬¡æ•¸)ï¼š
    {json.dumps(error_list, ensure_ascii=False)}
    
    è«‹æ ¹æ“šé€™äº›å–®å­—ï¼Œåˆ†æå­¸ç”Ÿçš„ç™¼éŸ³å¼±é»ï¼š
    1. **æ¯éŸ³å•é¡Œ**ï¼šæ˜¯å¦å¸¸æ··æ·†é•·çŸ­æ¯éŸ³ (å¦‚ /i/ vs /Éª/)ï¼Ÿ
    2. **å­éŸ³å•é¡Œ**ï¼šæ˜¯å¦æœ‰ç‰¹å®šå­éŸ³ç™¼ä¸å¥½ (å¦‚ /th/, /l/, /r/)ï¼Ÿ
    3. **é‡éŸ³èˆ‡ç¯€å¥**ï¼šæ˜¯å¦å¤šéŸ³ç¯€å–®å­—å®¹æ˜“å‡ºéŒ¯ï¼Ÿ
    4. **æ”¹å–„è¨ˆç•«**ï¼šçµ¦å‡º 3 å€‹å…·é«”çš„ç·´ç¿’å»ºè­°ã€‚
    
    è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œå°ˆæ¥­ä¸”å…·é«”åœ°å›ç­”ã€‚
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt, stream=False)
        return response.text
    except Exception as e:
        return f"å ±å‘Šç”Ÿæˆå¤±æ•—: {str(e)}"

def generate_review_report(api_key, model_name, stats_data):
    if not api_key: return "âš ï¸ è«‹å…ˆè¼¸å…¥ API Keyã€‚"
    error_logs = []
    for topic, data in stats_data.items():
        if "errors" in data and data["errors"]:
            examples = data["errors"][-3:]
            for ex in examples:
                error_logs.append(f"é¡Œå‹: {topic} | å­¸ç”Ÿå¯«: {ex['user']} | æ­£è§£: {ex['ans']} | AIè©•èª: {ex['feedback']}")

    if not error_logs:
        return "ğŸ‰ å¤ªæ£’äº†ï¼ç›®å‰çš„è¨˜éŒ„ä¸­æ²’æœ‰ç™¼ç¾éŒ¯èª¤ï¼Œè«‹ç¹¼çºŒä¿æŒï¼"

    prompt = f"""
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è‹±æ–‡å®¶æ•™ã€‚ä»¥ä¸‹æ˜¯å­¸ç”Ÿæœ€è¿‘çš„æ–‡æ³•ç·´ç¿’éŒ¯èª¤ç´€éŒ„ï¼š
    {json.dumps(error_logs, ensure_ascii=False, indent=2)}
    è«‹æ ¹æ“šé€™äº›éŒ¯èª¤ï¼Œç”Ÿæˆä¸€ä»½ã€Œå­¸ç¿’è¨ºæ–·å ±å‘Šã€ï¼š
    1. **éŒ¯èª¤æ¨¡å¼åˆ†æ**ï¼šå­¸ç”Ÿæ˜¯å¦æœ‰ç‰¹å®šçš„ç›²é»ï¼Ÿ
    2. **é‡é»è¤‡ç¿’å»ºè­°**ï¼šé‡å°ä¸Šè¿°ç›²é»ï¼Œçµ¦å‡º 3 å€‹å…·é«”çš„æ–‡æ³•è¤‡ç¿’é‡é»ã€‚
    3. **é¼“å‹µçš„è©±**ï¼šçµ¦å­¸ç”Ÿæ­£å‘çš„é¼“å‹µã€‚
    è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œèªæ°£æº«æŸ”å°ˆæ¥­ã€‚
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt, stream=False)
        return response.text
    except Exception as e:
        return f"å ±å‘Šç”Ÿæˆå¤±æ•—: {str(e)}"

@st.cache_data(show_spinner=False)
def get_word_info(_api_key, model_name, word, sentence):
    if not _api_key: return "âš ï¸ è«‹è¼¸å…¥ Google API Key"
    try:
        genai.configure(api_key=_api_key)
        model = genai.GenerativeModel(model_name)
        prompt = f"è§£é‡‹å–®å­— '{word}' åœ¨å¥å­ '{sentence}' ä¸­çš„æ„æ€ã€‚æ ¼å¼ï¼šğŸ”Š[{word}] KKéŸ³æ¨™\\nğŸ·ï¸[è©æ€§]\\nğŸ’¡[ç¹ä¸­æ„æ€](ç°¡æ½”)"
        responses = model.generate_content(prompt, stream=False)
        return responses.text
    except Exception as e:
        return handle_ai_error(e, model_name)

def generate_quiz(api_key, model_name, word):
    if not api_key: return "éŒ¯èª¤ï¼šæœªæª¢æ¸¬åˆ° API Key"
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        prompt = f"""
        è«‹é‡å°è‹±æ–‡å–®å­— "{word}" è¨­è¨ˆä¸€å€‹ã€Œæ‹¼å­—å¡«ç©ºé¡Œã€ã€‚
        Q: [è‹±æ–‡å¥å­ï¼Œå°‡ "{word}" é€™å€‹å­—æŒ–ç©ºï¼Œç”¨ `______ (è©²å–®å­—çš„ç¹é«”ä¸­æ–‡æ„æ€)` æç¤ºã€‚]
        A: [æ•´å¥è‹±æ–‡å¥å­çš„ç¹é«”ä¸­æ–‡ç¿»è­¯]
        """
        responses = model.generate_content(prompt, stream=False)
        raw_text = responses.text.strip()
        if "Q:" in raw_text: return raw_text[raw_text.find("Q:"):]
        else: return raw_text
    except Exception as e:
        return handle_ai_error(e, model_name)

def generate_grammar_batch(api_key, model_name, count=10):
    if not api_key: return None, "éŒ¯èª¤ï¼šæœªè¼¸å…¥ API Key"
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        topics = [
            "ç¾åœ¨å¼ Beå‹•è©è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "ç¾åœ¨å¼ Beå‹•è©è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "éå»å¼ Beå‹•è©è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "éå»å¼ Beå‹•è©è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "ç¾åœ¨ç°¡å–®å¼ ä¸€èˆ¬å‹•è©è‚¯å®šå¥ -> æ”¹å¦å®šå¥ (do/does)", "ç¾åœ¨ç°¡å–®å¼ ä¸€èˆ¬å‹•è©è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥ (do/does)",
            "éå»ç°¡å–®å¼ ä¸€èˆ¬å‹•è©è‚¯å®šå¥ -> æ”¹å¦å®šå¥ (did)", "éå»ç°¡å–®å¼ ä¸€èˆ¬å‹•è©è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥ (did)",
            "ç¾åœ¨é€²è¡Œå¼ è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "ç¾åœ¨é€²è¡Œå¼ è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "éå»é€²è¡Œå¼ è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "éå»é€²è¡Œå¼ è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "There is/are è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "There is/are è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "There was/were è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "There was/were è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "æƒ…æ…‹å‹•è© (can/may/must) è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "æƒ…æ…‹å‹•è© (can/may/must) è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "ç¾åœ¨ç°¡å–®å¼ Yes/Noç–‘å•å¥ -> æ”¹Wh-ç–‘å•å¥", "éå»ç°¡å–®å¼ Yes/Noç–‘å•å¥ -> æ”¹Wh-ç–‘å•å¥",
            "Will æœªä¾†å¼è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "Will æœªä¾†å¼è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "Be going to æœªä¾†å¼è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "Be going to æœªä¾†å¼è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "ç¾åœ¨ç°¡å–®å¼è‚¯å®šå¥ -> æ”¹éå»ç°¡å–®å¼", "éå»ç°¡å–®å¼è‚¯å®šå¥ -> æ”¹ç¾åœ¨ç°¡å–®å¼",
            "å½¢å®¹è©æ¯”è¼ƒç´šå¥å­ -> æ”¹æœ€é«˜ç´š", "å½¢å®¹è©æœ€é«˜ç´šå¥å­ -> æ”¹æ¯”è¼ƒç´š",
            "ç¥ˆä½¿å¥ -> æ”¹ç¦®è²Œè«‹æ±‚ (please/could you)",
            "ç¾åœ¨ç°¡å–®å¼ ä¸»å‹•èªæ…‹ -> æ”¹è¢«å‹•èªæ…‹", "ç¾åœ¨ç°¡å–®å¼ è¢«å‹•èªæ…‹ -> æ”¹ä¸»å‹•èªæ…‹",
            "éå»ç°¡å–®å¼ ä¸»å‹•èªæ…‹ -> æ”¹è¢«å‹•èªæ…‹", "éå»ç°¡å–®å¼ è¢«å‹•èªæ…‹ -> æ”¹ä¸»å‹•èªæ…‹",
            "ç¾åœ¨å®Œæˆå¼ è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "ç¾åœ¨å®Œæˆå¼ è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥", "ç¾åœ¨å®Œæˆå¼ è‚¯å®šå¥ -> æ”¹Wh-ç–‘å•å¥",
            "éå»å®Œæˆå¼ è‚¯å®šå¥ -> æ”¹å¦å®šå¥", "éå»å®Œæˆå¼ è‚¯å®šå¥ -> æ”¹Yes/Noç–‘å•å¥",
            "ç¬¬ä¸€æ¢ä»¶å¥ (æœªä¾†å¯èƒ½) -> æ”¹å¦å®šå¥", "ç¬¬äºŒæ¢ä»¶å¥ (å‡è¨­) -> æ”¹å¦å®šå¥",
            "é—œä¿‚å­å¥ (who/which/that) -> æ”¹æˆå…©å€‹ç°¡å–®å¥",
            "Because å› æœå¥ -> æ”¹æˆ So çµæœå¥",
            "é€£æ¥è©å¥å­ (and/but/or) -> æ”¹ç”¨å…¶ä»–é€£æ¥è©",
            "Some çš„å¥å­ -> æ”¹æˆ Any (å¦å®š/ç–‘å•)",
            "Much/Many çš„å¥å­ -> æ”¹æˆ A lot of/Lots of",
            "Few/Little çš„å¥å­ -> æ”¹æˆ Not many/Not much",
            "Have to ç¾©å‹™å¥ -> æ”¹æˆ Must", "Can èƒ½åŠ›å¥ -> æ”¹æˆ Could (éå»å¼)",
            "Will é æ¸¬å¥ -> æ”¹æˆ Be going to è¨ˆåŠƒå¥",
            "Too/Enough å¥å­ -> æ”¹å¯«", "æ„Ÿå˜†å¥ (How/What) -> æ”¹æˆé™³è¿°å¥",
            "ä»‹ç³»è©å¥å­ -> æ”¹æ›ä»‹ç³»è©", "å† è©å¥å­ -> æ”¹ç„¡å† è©",
            "æ‰€æœ‰æ ¼å¥å­ -> æ”¹ Of çµæ§‹", "åèº«ä»£åè©å¥å­ -> æ”¹ä¸€èˆ¬ä»£åè©",
            "ç¾åœ¨é€²è¡Œå¼ (æœªä¾†è¨ˆåŠƒ) -> æ”¹ Be going to",
            "é »ç‡å‰¯è©å¥å­ -> æ”¹è®Šä½ç½®", "å‰¯è©æ¯”è¼ƒç´šå¥å­ -> æ”¹ as...as",
            "é™„åŠ ç–‘å•å¥ (Tag Question) -> æ”¹å®Œæ•´ç–‘å•å¥",
            "é–“æ¥å¼•èª (Reported Speech) -> æ”¹ç›´æ¥å¼•èª (Direct Speech)"
        ]
        
        prompt = f"""
        è«‹ç”¢ç”Ÿ {count} å€‹è‹±æ–‡å¥å‹æ”¹å¯«ç·´ç¿’é¡Œã€‚
        è«‹å¾ä»¥ä¸‹ç¯„åœä¸­éš¨æ©ŸæŒ‘é¸ä¸åŒçš„é¡Œå‹ (ä¸è¦é‡è¤‡)ï¼š
        {json.dumps(topics, ensure_ascii=False)}
        
        è«‹åš´æ ¼ä½¿ç”¨ JSON æ ¼å¼å›å‚³ä¸€å€‹ List (åˆ—è¡¨)ï¼Œç‰©ä»¶æ¬„ä½å¿…é ˆåŒ…å« 'topic' ä»¥ä¾¿çµ±è¨ˆã€‚æ ¼å¼å¦‚ä¸‹ï¼š
        [
            {{"topic": "æ‰€é¸çš„é¡Œå‹åç¨±", "source": "åŸå§‹å¥å­", "task": "æ”¹å¯«è¦æ±‚", "answer": "æ­£ç¢ºç­”æ¡ˆ"}},
            {{"topic": "...", "source": "...", "task": "...", "answer": "..."}}
        ]
        ä¸éœ€è¦ Markdown æ¨™è¨˜ï¼Œç›´æ¥å›å‚³ç´” JSON æ–‡å­—ã€‚
        """
        
        responses = model.generate_content(prompt, stream=False)
        raw_text = responses.text.strip()
        
        if "```json" in raw_text:
            raw_text = raw_text.split("```json")[1].split("```")[0].strip()
        elif "```" in raw_text:
            raw_text = raw_text.split("```")[1].strip()
            
        questions = json.loads(raw_text)
        return questions, None
        
    except Exception as e:
        return None, handle_ai_error(e, model_name)

def check_grammar_answer(api_key, model_name, question, user_answer, correct_answer):
    if not api_key: return False, "ç„¡æ³•è©•åˆ†"
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        prompt = f"""
        é¡Œç›®ï¼š"{question}"
        è¦æ±‚ç›®æ¨™ï¼š"{correct_answer}"
        å­¸ç”Ÿå›ç­”ï¼š"{user_answer}"
        
        è«‹åˆ¤æ–·å­¸ç”Ÿçš„å›ç­”æ˜¯å¦æ­£ç¢ºã€‚
        1. **åš´æ ¼æª¢æŸ¥æ‹¼å­—**ï¼šå¦‚æœæœ‰ä»»ä½•å–®å­—æ‹¼éŒ¯ (Typo)ï¼Œè«‹ç›´æ¥è¦–ç‚ºéŒ¯èª¤ï¼Œä¸¦æ˜ç¢ºæŒ‡å‡ºå“ªå€‹å­—æ‹¼éŒ¯ã€‚
        2. æ–‡æ³•çµæ§‹å¿…é ˆæ­£ç¢ºã€‚
        
        è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼š
        {{
            "is_correct": true æˆ– false,
            "feedback": "é€™è£¡å¯«ç¹é«”ä¸­æ–‡çš„è©•èªã€è®šç¾æˆ–ç³¾æ­£å…§å®¹"
        }}
        ä¸éœ€è¦ Markdownã€‚
        """
        responses = model.generate_content(prompt, stream=False)
        text = responses.text.strip()
        
        if "```json" in text: text = text.split("```json")[1].split("```")[0].strip()
        elif "```" in text: text = text.split("```")[1].strip()
            
        result = json.loads(text)
        return result.get("is_correct", False), result.get("feedback", "è§£æéŒ¯èª¤")
        
    except Exception as e:
        return False, f"è©•åˆ†å¤±æ•—: {str(e)}"

def get_spelling_hint(word, attempts):
    length = len(word)
    if length <= 3:
        if attempts == 1: return f"_ " * length + f"({length}å€‹å­—æ¯)"
        else: return f"{word[0]} " + "_ " * (length - 1)
    else:
        if attempts == 1: return f"_ " * length + f"({length}å€‹å­—æ¯)"
        elif attempts == 2: return f"{word[0]} " + "_ " * (length - 1)
        elif attempts == 3: return f"{word[0]} " + "_ " * (length - 2) + f" {word[-1]}"
        else:
            reveal = min(attempts, length - 1)
            hint_str = ""
            for i in range(length):
                if i < reveal: hint_str += f"{word[i]} "
                elif i == length - 1: hint_str += f"{word[-1]}"
                else: hint_str += "_ "
            return hint_str

def speak_google(text, speed=1.0):
    try:
        clean_text = text.replace("ğŸŒŸ Full Text Review: ", "")
        is_slow = speed < 1.0
        tts = gTTS(text=clean_text, lang='en', slow=is_slow)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
            tts.save(fp.name)
            return fp.name
    except: return None

def speak_offline(text, speed=1.0):
    if not HAS_OFFLINE_TTS: return None
    try:
        clean_text = text.replace("ğŸŒŸ Full Text Review: ", "")
        engine = pyttsx3.init()
        engine.setProperty('rate', int(175 * speed))
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
            engine.save_to_file(clean_text, fp.name)
            engine.runAndWait()
            return fp.name
    except: return None

def get_offline_voices():
    try:
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        return {v.name: v.id for v in voices}
    except: return {}

def split_text_smartly(text):
    text = text.strip()
    text = re.sub(r'(?m)^\d+\s+', '', text)
    text = re.sub(r'(?m)^[A-Z]:\s+', '', text)
    clean_text = text.replace('\n', ' ')
    raw_sentences = re.split(r'(?<=[.!?])\s+', clean_text)
    segments = [s.strip() for s in raw_sentences if len(s.strip()) > 0]
    if len(segments) > 0:
        segments.append("ğŸŒŸ Full Text Review: " + clean_text)
    return segments

def check_similarity_visual(target, user_text):
    if not user_text: return 0, "ç„¡èªéŸ³è¼¸å…¥"
    target_clean = target.replace("ğŸŒŸ Full Text Review: ", "")
    t_words = re.findall(r"\w+", target_clean.lower())
    u_words = re.findall(r"\w+", user_text.lower())
    matcher = difflib.SequenceMatcher(None, t_words, u_words)
    score = matcher.ratio() * 100
    html_parts = []
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        t_segment = " ".join(t_words[i1:i2])
        u_segment = " ".join(u_words[j1:j2])
        if tag == 'equal': html_parts.append(f'<span style="color:green;font-weight:bold;">{t_segment}</span>')
        elif tag == 'replace': html_parts.append(f'<span style="color:red;text-decoration:line-through;">{t_segment}</span> <span style="color:gray;">({u_segment})</span>')
        elif tag == 'delete': html_parts.append(f'<span style="background-color:#ffcccc;color:red;">{t_segment}</span>')
        elif tag == 'insert': html_parts.append(f'<span style="color:gray;font-style:italic;">{u_segment}</span>')
    return score, " ".join(html_parts)

# [ä¿®æ”¹] æ›´æ–°ç‚ºå›å‚³ç›¸é—œä¿‚æ•¸ (Correlation Coefficient)
def plot_and_get_trend(teacher_path, student_path):
    if not HAS_LIBROSA: return None, 0, 0
    try:
        y_t, sr_t = librosa.load(teacher_path, sr=22050)
        f0_t, _, _ = librosa.pyin(y_t, fmin=50, fmax=400, frame_length=2048)
        y_s, sr_s = librosa.load(student_path, sr=22050)
        f0_s, _, _ = librosa.pyin(y_s, fmin=50, fmax=400, frame_length=2048)
        if f0_t is None or f0_s is None: return None, 0, 0
        def normalize(f0):
            valid = f0[~np.isnan(f0)]
            if len(valid) == 0: return np.array([])
            return (valid - np.mean(valid)) / (np.std(valid) + 1e-6)
        norm_t = normalize(f0_t)
        norm_s = normalize(f0_s)
        if len(norm_t) == 0 or len(norm_s) == 0: return None, 0, 0
        from scipy.signal import resample
        norm_s_res = resample(norm_s, len(norm_t))
        
        # [ä¿®æ”¹] è¨ˆç®—ç›¸é—œä¿‚æ•¸ (Correlation) -1 åˆ° 1
        correlation = np.corrcoef(norm_t, norm_s_res)[0, 1]
        
        # ç‚ºäº†ç›¸å®¹åŸæœ¬çš„ fig ç¹ªåœ–ï¼Œæˆ‘å€‘é‚„æ˜¯ç•«å‡ºä¾†
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots(figsize=(8, 2))
        ax.plot(norm_t, label='Teacher', color='#42a5f5', linewidth=2)
        ax.plot(norm_s_res, label='You', color='#ffa726', linestyle='--', linewidth=2)
        ax.axis('off')
        plt.close(fig)
        
        return fig, correlation, 0 # å›å‚³ç›¸é—œä¿‚æ•¸
    except: return None, 0, 0

def create_backup_zip():
    vocab = load_vocab()
    grammar = load_grammar_stats()
    pronunciation_data = [v for v in vocab if v.get('pronunciation_errors', 0) > 0]
    
    buffer = io.BytesIO()
    with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as z:
        z.writestr("vocab_book.json", json.dumps(vocab, ensure_ascii=False, indent=4))
        z.writestr("grammar_stats.json", json.dumps(grammar, ensure_ascii=False, indent=4))
        z.writestr("pronunciation_history.json", json.dumps(pronunciation_data, ensure_ascii=False, indent=4))
    
    return buffer.getvalue()

def generate_story_from_vocab(api_key, model_name, vocab_list, target_length):
    total_vocab_count = len(vocab_list)
    
    if total_vocab_count < 10:
        num_words_to_pick = total_vocab_count
    else:
        num_words_to_pick = random.randint(10, min(15, total_vocab_count))
        
    selected_vocab = random.sample(vocab_list, num_words_to_pick)
    words_str = ", ".join([v['word'] for v in selected_vocab])
    
    themes = [
        "å‹•ç‰©ç™¾ç§‘ (Animals & Nature) - ä»‹ç´¹æŸç¨®å‹•ç‰©æˆ–è‡ªç„¶ç¾è±¡",
        "ä¸–ç•Œæ—…éŠ (Travel & Geography) - ä»‹ç´¹æŸå€‹åœ‹å®¶ã€åŸå¸‚æˆ–æ™¯é»",
        "ç”Ÿæ´»æ—¥è¨˜ (Daily Life Diary) - æè¿°ä¸€å¤©çš„ç”Ÿæ´»ã€å·¥ä½œæˆ–å­¸ç¿’",
        "å†·çŸ¥è­˜ (Fun Facts & Trivia) - åˆ†äº«æœ‰è¶£æˆ–ä¸ç‚ºäººçŸ¥çš„äº‹å¯¦",
        "å¥åº·èˆ‡ç§‘å­¸ (Health & Science) - ä»‹ç´¹å¥åº·ç¿’æ…£æˆ–ç§‘å­¸å°çŸ¥è­˜",
        "äººç‰©æ•…äº‹ (Biography) - ç°¡çŸ­æè¿°æŸå€‹äººçš„ç¶“æ­·",
        "ç¾é£Ÿä»‹ç´¹ (Food & Culture) - ä»‹ç´¹æŸç¨®é£Ÿç‰©æˆ–é£²é£Ÿæ–‡åŒ–"
    ]
    selected_theme = random.choice(themes)

    prompt = f"""
    è«‹ä½¿ç”¨ä»¥ä¸‹è‹±æ–‡å–®å­—å¯«ä¸€ç¯‡ç´„ {target_length} å­—çš„çŸ­æ–‡ï¼š
    å–®å­—åˆ—è¡¨: {words_str}
    
    æŒ‡å®šä¸»é¡Œï¼š{selected_theme}
    
    è¦æ±‚ï¼š
    1. æ•…äº‹é€šé †æœ‰è¶£ï¼Œå¯Œæœ‰æ•™è‚²æ„ç¾©æˆ–ç”Ÿæ´»æ„Ÿã€‚
    2. é©åˆè‹±èªå£èªªè·Ÿè®€ç·´ç¿’ã€‚
    3. å¥å­çµæ§‹å¤šæ¨£åŒ–ï¼Œä½†ä¸è¦å¤ªé•·ã€‚
    4. ç›´æ¥æä¾›è‹±æ–‡æ–‡ç« å…§å®¹ï¼Œä¸è¦æœ‰æ¨™é¡Œã€ä¸­æ–‡ç¿»è­¯æˆ–é¡å¤–èªªæ˜ã€‚
    5. **åš´æ ¼ç¦æ­¢**åœ¨æ–‡ç« ä¸­å°å–®å­—ä½¿ç”¨æ˜Ÿè™Ÿ(*)ã€ç²—é«”æˆ–ä»»ä½•æ¨™è¨˜ï¼Œè«‹è¼¸å‡ºä¹¾æ·¨çš„ç´”æ–‡å­—ã€‚
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(prompt, stream=False)
        return response.text.strip()
    except Exception as e:
        return f"Error: {str(e)}"

def get_next_pronounce_word(vocab_list):
    if not vocab_list: return None
    
    multi = [v for v in vocab_list if count_syllables(v["word"]) > 1]
    single = [v for v in vocab_list if count_syllables(v["word"]) == 1]
    
    target = None
    
    if multi and single:
        if random.random() < 0.6:
            target = random.choice(multi)
        else:
            target = random.choice(single)
    elif multi:
        target = random.choice(multi)
    elif single:
        target = random.choice(single)
    else:
        target = random.choice(vocab_list)
        
    return target

# ==========================================
# 6. ä¸»ç¨‹å¼ä»‹é¢
# ==========================================
inject_custom_css()

# åˆå§‹åŒ– State
if 'available_models' not in st.session_state: st.session_state.available_models = []
if 'game_active' not in st.session_state: st.session_state.game_active = False
if 'sentences' not in st.session_state: st.session_state.sentences = []
if 'current_index' not in st.session_state: st.session_state.current_index = 0
if 'current_word_info' not in st.session_state: st.session_state.current_word_info = None
if 'current_word_target' not in st.session_state: st.session_state.current_word_target = None
if 'current_word_audio' not in st.session_state: st.session_state.current_word_audio = None
if 'current_audio_path' not in st.session_state: st.session_state.current_audio_path = None
if 'quiz_data' not in st.session_state: st.session_state.quiz_data = None
if 'quiz_state' not in st.session_state: st.session_state.quiz_state = "QUESTION"
if 'is_finished' not in st.session_state: st.session_state.is_finished = False
if 'segment_times' not in st.session_state: st.session_state.segment_times = {}
if 'start_time' not in st.session_state: st.session_state.start_time = None
if 'quiz_attempts' not in st.session_state: st.session_state.quiz_attempts = 0
if 'quiz_last_msg' not in st.session_state: st.session_state.quiz_last_msg = ""
if 'quiz_error_counted' not in st.session_state: st.session_state.quiz_error_counted = False
if 'last_app_mode' not in st.session_state: st.session_state.last_app_mode = None
# [å¯«ä½œç·´ç¿’ State]
if 'grammar_queue' not in st.session_state: st.session_state.grammar_queue = []
if 'grammar_index' not in st.session_state: st.session_state.grammar_index = 0
if 'grammar_feedback' not in st.session_state: st.session_state.grammar_feedback = ""
if 'review_report' not in st.session_state: st.session_state.review_report = None 
# [çœ‹å­—ç™¼éŸ³ State]
if 'pronounce_data' not in st.session_state: st.session_state.pronounce_data = None
if 'pronounce_attempts' not in st.session_state: st.session_state.pronounce_attempts = 0
if 'pronounce_feedback' not in st.session_state: st.session_state.pronounce_feedback = ""
if 'pronounce_report' not in st.session_state: st.session_state.pronounce_report = None
# [AI è€å¸«è¬›è§£ Persistence]
if 'full_text_explanation' not in st.session_state: st.session_state.full_text_explanation = None

# [æ–°å¢] éŒ„éŸ³çµ„ä»¶çš„å‹•æ…‹ Key
if 'pronounce_rec_key' not in st.session_state: st.session_state.pronounce_rec_key = 0

if 'saved_api_key' not in st.session_state:
    if os.path.exists(KEY_FILE):
        with open(KEY_FILE, "r") as f: st.session_state.saved_api_key = f.read().strip()
    else: st.session_state.saved_api_key = ""

# --- å´é‚Šæ¬„ (ä¿®æ­£ç‰ˆï¼šå…è¨±æ‰‹å‹•è¼¸å…¥æ¨¡å‹) ---
with st.sidebar:
    st.title("âš™ï¸ è¨­å®š")
    google_api_key = st.text_input("ğŸ”‘ Google API Key", value=st.session_state.saved_api_key, type="password")
    if google_api_key != st.session_state.saved_api_key:
        with open(KEY_FILE, "w") as f: f.write(google_api_key)
        st.session_state.saved_api_key = google_api_key
        st.session_state.available_models = []

    if google_api_key:
        # 1. å˜—è©¦æŠ“å–å¯ç”¨æ¨¡å‹
        if not st.session_state.available_models:
            try:
                genai.configure(api_key=google_api_key)
                all_models = list(genai.list_models())
                st.session_state.available_models = [m.name.replace("models/", "") for m in all_models if "generateContent" in m.supported_generation_methods]
                st.session_state.available_models.sort()
            except:
                # è¬ä¸€æŠ“ä¸åˆ°ï¼Œè‡³å°‘çµ¦å¹¾å€‹å‚™é¸
                st.session_state.available_models = ["gemini-1.5-flash", "gemini-1.5-flash-8b", "gemini-1.5-pro"]
        
        # 2. é¡¯ç¤ºä¸‹æ‹‰é¸å–®
        if st.session_state.available_models:
            try:
                # è©¦è‘—é é¸ flash
                default_idx = 0
                for i, m in enumerate(st.session_state.available_models):
                    if "flash" in m and "exp" not in m: default_idx = i; break
                
                selected_model_drop = st.selectbox("ğŸ¤– é¸æ“‡ AI æ¨¡å‹", st.session_state.available_models, index=default_idx)
            except:
                selected_model_drop = st.selectbox("ğŸ¤– é¸æ“‡ AI æ¨¡å‹", st.session_state.available_models)
        else:
            selected_model_drop = "gemini-1.5-flash"

        # 3. æ‰‹å‹•è¼¸å…¥åŠŸèƒ½ (è§£æ±º API é¡åº¦èª¤åˆ¤æˆ–é¸å–®ç¼ºå¤±å•é¡Œ)
        use_manual = st.checkbox("ğŸ“ æ‰‹å‹•è¼¸å…¥æ¨¡å‹åç¨± (è‹¥é¸å–®ç„¡æ³•ä½¿ç”¨è«‹å‹¾é¸)")
        if use_manual:
            selected_model = st.text_input("æ‰‹å‹•è¼¸å…¥æ¨¡å‹", value="gemini-1.5-flash-8b")
            st.caption("ğŸ’¡ å»ºè­°å˜—è©¦ï¼š`gemini-1.5-flash-8b` æˆ– `gemini-1.5-pro` (ä»˜è²»å¸³è™Ÿè«‹ç”¨é€™äº›)")
        else:
            selected_model = selected_model_drop
            
        st.info(f"ğŸš€ ç•¶å‰ä½¿ç”¨: `{selected_model}`")
    else:
        st.warning("ğŸ‘‰ è«‹è¼¸å…¥ API Key æ‰èƒ½ä½¿ç”¨ AI åŠŸèƒ½ã€‚")
    
    st.markdown("---")
    app_mode = st.radio("é¸æ“‡æ¨¡å¼", ["ğŸ“– è·Ÿè®€ç·´ç¿’", "ğŸ“ æ‹¼å­—æ¸¬é©— (AIå‡ºé¡Œ)", "ğŸ‘‚ è‹±è½æ‹¼å­—æ¸¬é©—", "âœï¸ å¥å‹æ”¹å¯«ç·´ç¿’", "ğŸ—£ï¸ çœ‹å­—ç™¼éŸ³æŒ‘æˆ°", "ğŸ¤– AI è‡ªå‹•ç”ŸæˆçŸ­æ–‡è·Ÿè®€", "ğŸ“š å–®å­—åº«æª¢è¦–"], index=0)
    
    if st.session_state.last_app_mode != app_mode:
        st.session_state.quiz_data = None
        st.session_state.quiz_state = "QUESTION"
        st.session_state.quiz_attempts = 0
        st.session_state.quiz_last_msg = ""
        st.session_state.grammar_queue = [] 
        st.session_state.grammar_index = 0
        st.session_state.grammar_feedback = ""
        st.session_state.review_report = None
        st.session_state.pronounce_data = None
        st.session_state.pronounce_attempts = 0
        st.session_state.pronounce_feedback = ""
        st.session_state.pronounce_report = None
        st.session_state.full_text_explanation = None # é‡ç½®è¬›è§£
        # å¦‚æœåˆ‡æ›æ¨¡å¼ï¼Œä¹Ÿè¦é‡ç½®è·Ÿè®€ç‹€æ…‹
        st.session_state.game_active = False
        st.session_state.last_app_mode = app_mode
        st.rerun()

    st.markdown("---")
    if HAS_OFFLINE_TTS:
        tts_mode = st.radio("ç™¼éŸ³å¼•æ“", ["â˜ï¸ ç·šä¸Š (Google)", "ğŸ’» é›¢ç·š (Windows)"], index=0)
    else:
        tts_mode = "â˜ï¸ ç·šä¸Š (Google)"
    voice_speed = st.slider("èªé€Ÿ", 0.5, 1.5, 1.0, 0.1)
    
    # [æ–°å¢] å„²å­˜çš„çŸ­æ–‡åˆ—è¡¨ (åŒ…å«è¼‰å…¥ç­†è¨˜)
    st.markdown("---")
    with st.expander("ğŸ“‚ å·²å„²å­˜çš„çŸ­æ–‡ (Storybook)", expanded=False):
        saved_stories = load_stories()
        if saved_stories:
            for s in saved_stories:
                if st.button(f"ğŸ“– {s['title']} ({s['date']})", key=s['id'], use_container_width=True):
                    # è¼‰å…¥æ•…äº‹åˆ°è·Ÿè®€æ¨¡å¼
                    s_split = split_text_smartly(s['content'])
                    if s_split:
                        st.session_state.sentences = s_split
                        st.session_state.current_index = 0
                        st.session_state.game_active = True
                        st.session_state.is_finished = False
                        st.session_state.start_time = time.time()
                        st.session_state.segment_times = {}
                        
                        # [é—œéµä¿®æ”¹] è¼‰å…¥ç­†è¨˜
                        st.session_state.full_text_explanation = s.get("explanation")
                        
                        # å¼·åˆ¶è·³è½‰åˆ°è·Ÿè®€æ¨¡å¼
                        st.toast("ğŸ“– å·²è¼‰å…¥çŸ­æ–‡èˆ‡ç­†è¨˜ï¼è«‹åˆ‡æ›åˆ°ã€ŒğŸ¤– AI è‡ªå‹•ç”ŸæˆçŸ­æ–‡è·Ÿè®€ã€æˆ–ã€ŒğŸ“– è·Ÿè®€ç·´ç¿’ã€é–‹å§‹ç·´ç¿’ã€‚")
        else:
            st.caption("å°šæœªå„²å­˜ä»»ä½•çŸ­æ–‡ã€‚")

    if st.session_state.segment_times:
        st.markdown("---")
        st.markdown("### â±ï¸ ç·´ç¿’æ™‚é–“çµ±è¨ˆ")
        for idx, duration in st.session_state.segment_times.items():
            label = "å…¨æ–‡è¤‡ç¿’" if idx == len(st.session_state.sentences)-1 and "Full Text" in st.session_state.sentences[idx] else f"ç¬¬ {idx+1} æ®µ"
            st.caption(f"{label}: {duration:.1f} ç§’")

    st.markdown("---")
    with st.expander("ğŸ”¥ æ˜“éŒ¯å–®å­—æ’è¡Œæ¦œ", expanded=True):
        vocab_list = load_vocab()
        error_list = [v for v in vocab_list if v.get("error_count", 0) > 0]
        error_list.sort(key=lambda x: x["error_count"], reverse=True)
        if error_list:
            for i, v in enumerate(error_list[:5]): 
                st.write(f"**{i+1}. {v['word']}** (éŒ¯ {v['error_count']} æ¬¡)")
        else:
            st.caption("ç›®å‰æ²’æœ‰æ‹¼éŒ¯ç´€éŒ„ï¼Œç¹¼çºŒä¿æŒï¼")

    with st.expander("ğŸ’¾ å–®å­—åº«ç®¡ç† (ä¸Šå‚³é‚„åŸ)", expanded=False):
        st.write(f"ç›®å‰å–®å­—ï¼š**{len(vocab_list)}** å€‹")
        
        uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šå‚³å–®å­—åº« (vocab_book.json)", type=["json"], key="json_restore_vocab")
        if uploaded_file:
            try:
                data = json.load(uploaded_file)
                save_vocab_to_disk(data)
                st.success(f"å·²é‚„åŸ {len(data)} å€‹å–®å­—ï¼")
                st.rerun()
            except:
                 st.error("é‚„åŸå¤±æ•—ï¼Œæ ¼å¼éŒ¯èª¤ã€‚")

        st.markdown("---")
        st.caption("âœ¨ **æ‰¹æ¬¡åŒ¯å…¥æ–°å–®å­—** (TXT/CSV/æ–‡ç« ):")
        
        imported_file = st.file_uploader("ğŸ“‚ åŒ¯å…¥æ–‡ç« æˆ–å–®å­—åˆ—è¡¨ (TXT/CSV)", type=["txt", "csv"], key="batch_import_vocab")

        if imported_file:
            try:
                content = imported_file.read().decode("utf-8")
                words_to_add = process_imported_text(content)
                st.info(f"åµæ¸¬åˆ° **{len(words_to_add)}** å€‹å–®å­—ã€‚")
                
                if st.button(f"â• ç¢ºèªåŒ¯å…¥ {len(words_to_add)} å€‹å–®å­— (å¾…æŸ¥è©¢)", type="secondary", use_container_width=True, key="confirm_batch_import"):
                    count = 0
                    for word in words_to_add:
                        added = add_word_to_vocab(word, "å¾…æŸ¥è©¢: è«‹åœ¨è·Ÿè®€æ¨¡å¼ä¸‹é»æ“Šå–®å­—æŸ¥è©¢å®šç¾©")
                        if added:
                            count += 1
                    st.success(f"âœ… æˆåŠŸåŒ¯å…¥ {count} å€‹æ–°å–®å­—ï¼")
                    st.rerun()
            except Exception as e:
                st.error(f"æª”æ¡ˆè®€å–æˆ–è§£æå¤±æ•—: {e}")
        
        # [æ–°å¢] ç™¼éŸ³ç´€éŒ„é‚„åŸ
        st.markdown("---")
        st.caption("âœ¨ **é‚„åŸç™¼éŸ³ç·´ç¿’ç´€éŒ„**:")
        uploaded_pron = st.file_uploader("ğŸ“¤ ä¸Šå‚³ç™¼éŸ³ç´€éŒ„ (pronunciation_history.json)", type=["json"], key="restore_pron")
        if uploaded_pron:
            try:
                data_list = json.load(uploaded_pron)
                restored_count = restore_pronunciation_data(data_list)
                st.success(f"âœ… å·²é‚„åŸ {restored_count} ç­†ç™¼éŸ³ç´€éŒ„ï¼")
                st.rerun()
            except Exception as e:
                st.error(f"é‚„åŸå¤±æ•—: {str(e)}")

    with st.expander("ğŸ’¾ æ–‡æ³•ç·´ç¿’ç´€éŒ„ç®¡ç†", expanded=False):
        stats = load_grammar_stats()
        total_errors = sum(len(item.get("errors", [])) for item in stats.values())
        st.write(f"ç›®å‰ç´€éŒ„ï¼š**{len(stats)}** ç¨®é¡Œå‹")
        st.write(f"ç´¯è¨ˆéŒ¯èª¤ï¼š**{total_errors}** ç­†")
        
        uploaded_stats = st.file_uploader("ğŸ“¤ ä¸Šå‚³é‚„åŸç´€éŒ„ (grammar_stats.json)", type=["json"], key="grammar_restore")
        if uploaded_stats:
            try:
                data = json.load(uploaded_stats)
                with open(GRAMMAR_FILE, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False, indent=4)
                st.success(f"âœ… å·²é‚„åŸæ–‡æ³•ç´€éŒ„ï¼")
                st.rerun()
            except:
                st.error("é‚„åŸå¤±æ•—ï¼Œæ ¼å¼éŒ¯èª¤ã€‚")
    
    # [æ–°å¢] å…¨ç«™è³‡æ–™å‚™ä»½ (ZIP)
    st.markdown("---")
    with st.expander("ğŸ“¦ å…¨ç«™è³‡æ–™å‚™ä»½ (All-in-One)", expanded=True):
        st.caption("å°‡ å–®å­—åº«ã€æ–‡æ³•ç´€éŒ„ã€ç™¼éŸ³ç´€éŒ„ æ‰“åŒ…ä¸‹è¼‰ (ZIP)")
        if st.button("ğŸ“¥ ç”¢ç”Ÿå®Œæ•´å‚™ä»½æª”", type="primary"):
            zip_buffer = create_backup_zip()
            st.download_button(
                label="â¬‡ï¸ é»æ“Šä¸‹è¼‰ ZIP",
                data=zip_buffer,
                file_name=f"english_coach_full_backup_{int(time.time())}.zip",
                mime="application/zip"
            )

st.title("ğŸ¤ AI è‹±æ–‡æ•™ç·´ Pro (ä¸ƒåˆä¸€å®Œæ•´ç‰ˆ)")

# ==========================================
# æ¨¡å¼ A: è·Ÿè®€ç·´ç¿’
# ==========================================
if app_mode == "ğŸ“– è·Ÿè®€ç·´ç¿’":
    if not st.session_state.game_active:
        st.markdown('<div class="reading-box">æ­¡è¿ï¼è«‹è¼¸å…¥æ–‡ç« é–‹å§‹ç·´ç¿’ã€‚</div>', unsafe_allow_html=True)
        default_text = """1 Drug Store
A: Excuse me, Is there a drug store in this neighborhood?

B: Yes, There's a drug store on Main Street, across from the church.

2 Clinic
A: Excuse me, Is there a clinic?

B: Yes, next to the bank."""
        input_text = st.text_area("æ–‡ç« å…§å®¹ï¼š", value=default_text, height=200)
        
        if st.button("ğŸš€ é–‹å§‹ç·´ç¿’", type="primary", use_container_width=True):
            s = split_text_smartly(input_text)
            if s: 
                st.session_state.sentences = s
                st.session_state.current_index = 0
                st.session_state.game_active = True
                st.session_state.is_finished = False
                st.session_state.start_time = time.time()
                st.session_state.segment_times = {}
                st.session_state.full_text_explanation = None
                st.rerun()
    else:
        # --- é€™è£¡é–‹å§‹æ˜¯è·Ÿè®€ç·´ç¿’çš„æ ¸å¿ƒé‚è¼¯ (Mode A å’Œ Mode G å…±ç”¨) ---
        if st.session_state.is_finished:
            st.balloons()
            st.markdown("""
            <div class="backup-alert">
                <h2>ğŸ‰ ç·´ç¿’çµæŸï¼</h2>
                <p>åˆ¥å¿˜äº†å»å´é‚Šæ¬„ä¸‹è¼‰æ‚¨çš„å–®å­—åº«å‚™ä»½å–”ï¼</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.session_state.segment_times:
                max_time_idx = max(st.session_state.segment_times, key=st.session_state.segment_times.get)
                max_time_val = st.session_state.segment_times[max_time_idx]
                st.info(f"ğŸ’¡ åˆ†æï¼šæ‚¨åœ¨ç¬¬ {max_time_idx+1} æ®µèŠ±äº†æœ€å¤šæ™‚é–“ ({max_time_val:.1f}ç§’)ã€‚")

            if st.button("ğŸ”„ å†ç·´ä¸€æ¬¡ / å›åˆ°é¦–é "):
                st.session_state.game_active = False
                st.session_state.is_finished = False
                st.session_state.segment_times = {}
                st.rerun()
            st.stop()

        idx = st.session_state.current_index
        sentences = st.session_state.sentences
        target_sentence = sentences[idx]

        def switch_page(increment):
            end_time = time.time()
            duration = end_time - st.session_state.start_time
            if idx in st.session_state.segment_times:
                st.session_state.segment_times[idx] += duration
            else:
                st.session_state.segment_times[idx] = duration
            st.session_state.current_index += increment
            st.session_state.current_audio_path = None
            st.session_state.start_time = time.time()
            st.rerun()

        c1, c2, c3 = st.columns([1, 4, 1])
        with c1: 
            if st.button("â¬…ï¸ ä¸Šå¥", disabled=(idx==0), use_container_width=True):
                switch_page(-1)
        with c2: st.progress((idx+1)/len(sentences), text=f"é€²åº¦ï¼š{idx+1} / {len(sentences)}")
        with c3:
            is_last = (idx == len(sentences) - 1)
            btn_text = "å®Œæˆ ğŸ‰" if is_last else "ä¸‹å¥ â¡ï¸"
            if st.button(btn_text, use_container_width=True):
                if is_last:
                    switch_page(0) 
                    st.session_state.is_finished = True
                    st.rerun()
                else:
                    switch_page(1)
        
        if st.button("ğŸ ä¸­é€”çµæŸ", type="secondary", use_container_width=True):
             st.session_state.is_finished = True
             st.rerun()

        col_L, col_R = st.columns([1.5, 1], gap="large")

        with col_L:
            st.subheader("ğŸ“– é–±è®€")
            if "Full Text Review" in target_sentence:
                st.info("ğŸŒŸ æŒ‘æˆ°æ™‚é–“ï¼šå…¨æ–‡é€£è®€ï¼")
            
            display_text = target_sentence.replace("ğŸŒŸ Full Text Review: ", "")
            st.markdown(f'<div class="reading-box">{display_text}</div>', unsafe_allow_html=True)
            
            # [æ–°å¢åŠŸèƒ½] é‡å°å…¨æ–‡é€£è®€å€å¡Šçš„ AI è€å¸«è¬›è§£åŠŸèƒ½ + å„²å­˜æŒ‰éˆ•
            if "Full Text Review" in target_sentence:
                st.markdown("---")
                c_ai, c_save = st.columns([2, 1])
                
                with c_ai:
                    if st.button("ğŸ‘©â€ğŸ« è«‹ AI è€å¸«ç¿»è­¯ä¸¦è¬›è§£é‡é» (åˆå­¸è€…æ¨¡å¼)"):
                        with st.spinner("ğŸ‘©â€ğŸ« AI è€å¸«æ­£åœ¨åˆ†ææ¶æ§‹ã€å¥å‹èˆ‡æ–‡æ³•ï¼Œè«‹ç¨å€™..."):
                            explanation = get_ai_text_explanation(google_api_key, selected_model, display_text)
                            st.session_state.full_text_explanation = explanation # å­˜å…¥ State
                            st.success("åˆ†æå®Œæˆï¼")
                
                with c_save:
                    if st.button("ğŸ’¾ å„²å­˜é€™ç¯‡çŸ­æ–‡ (å«ç­†è¨˜)", type="secondary"):
                        result = save_story_to_disk(display_text, st.session_state.full_text_explanation)
                        if result == "UPDATED": st.toast("âœ… å·²æ›´æ–°ç­†è¨˜åˆ°ç¾æœ‰å­˜æª”ï¼")
                        elif result: st.toast("âœ… çŸ­æ–‡èˆ‡ç­†è¨˜å·²å„²å­˜ï¼")
                        else: st.toast("âš ï¸ å·²ç¶“å­˜éå›‰ï¼")

                # å¦‚æœ State ä¸­æœ‰è¬›è§£ï¼Œå‰‡é¡¯ç¤º (åŒ…å«å¤§å­—é«”åŸæ–‡)
                if st.session_state.full_text_explanation:
                    st.markdown("---")
                    st.markdown(f'<div class="story-text-large">{display_text}</div>', unsafe_allow_html=True)
                    st.markdown(st.session_state.full_text_explanation)
                    
                st.markdown("---")

            st.caption("ğŸ‘‡ é»æ“ŠæŸ¥å–®å­— (éœ€è¼¸å…¥ API Key)ï¼š")
            words = re.findall(r"\b\w+\b", display_text)
            cols = st.columns(5)
            for i, word in enumerate(words):
                if cols[i % 5].button(word, key=f"w_{idx}_{i}", disabled=not google_api_key):
                    st.session_state.current_word_target = word
                    with st.spinner("ğŸ” AI æŸ¥è©¢ä¸­..."):
                        # ä½¿ç”¨é¸æ“‡çš„æ¨¡å‹
                        info = get_word_info(google_api_key, selected_model, word, display_text)
                        st.session_state.current_word_info = info
                        if "æŸ¥è©¢å¤±æ•—" not in info and "è«‹è¼¸å…¥ API Key" not in info:
                            w_path = speak_google(word, 1.0)
                            if not w_path: w_path = speak_offline(word, 1.0)
                            st.session_state.current_word_audio = w_path
                        else:
                            st.session_state.current_word_audio = None
            
            if not google_api_key:
                 st.warning("ğŸ‘‰ è«‹å…ˆåœ¨å´é‚Šæ¬„è¼¸å…¥ API Keyï¼Œæ‰èƒ½ä½¿ç”¨å–®å­—æŸ¥è©¢åŠŸèƒ½ã€‚")

            if st.session_state.current_word_info:
                info_html = st.session_state.current_word_info.replace('\n', '<br>')
                st.markdown(f'<div class="definition-card">{info_html}</div>', unsafe_allow_html=True)
                
                c_p, c_s = st.columns([4, 1])
                with c_p:
                    if st.session_state.current_word_audio:
                        st.audio(st.session_state.current_word_audio, format='audio/mp3')
                with c_s:
                    if "æŸ¥è©¢å¤±æ•—" not in st.session_state.current_word_info and "è«‹è¼¸å…¥ API Key" not in st.session_state.current_word_info:
                        if st.button("â­ æ”¶è—åŠ å…¥å–®å­—åº«", use_container_width=True, type="primary"):
                            saved = add_word_to_vocab(st.session_state.current_word_target, st.session_state.current_word_info)
                            if saved: st.toast("âœ… å·²æˆåŠŸæ”¶è—ï¼")
                            else: st.toast("âš ï¸ å–®å­—åº«è£¡å·²ç¶“æœ‰å›‰ï¼")

            st.markdown("---")
            st.subheader("ğŸ—£ï¸ ç¤ºç¯„")
            if st.session_state.current_audio_path is None:
                path = None
                if "ç·šä¸Š" in tts_mode: path = speak_google(display_text, voice_speed)
                if not path: path = speak_offline(display_text, voice_speed)
                st.session_state.current_audio_path = path

            if st.session_state.current_audio_path:
                st.audio(st.session_state.current_audio_path, format="audio/mp3")
            else:
                st.warning("ç„¡æ³•ç”ŸæˆèªéŸ³")

        with col_R:
            st.subheader("ğŸ™ï¸ å£èªª")
            st.markdown(f'<div class="mobile-hint-card" style="white-space: pre-wrap;">ğŸ“– è·Ÿè®€ï¼š<br>{display_text}</div>', unsafe_allow_html=True)
            
            user_audio = st.audio_input("éŒ„éŸ³", key=f"rec_{idx}", disabled=not google_api_key)
            if not google_api_key:
                 st.warning("ğŸ‘‰ è«‹å…ˆè¼¸å…¥ API Keyï¼Œæ‰èƒ½ä½¿ç”¨å£èªªè©•åˆ†åŠŸèƒ½ã€‚")
            
            if user_audio and st.session_state.current_audio_path and google_api_key:
                with st.spinner("ğŸ¤– AI åˆ†æä¸­..."):
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(user_audio.read()); user_path = tmp.name
                    
                    u_text = transcribe_audio(user_path)
                    score_text, diff_html = check_similarity_visual(display_text, u_text)
                    fig, raw_pitch_score, correlation = plot_and_get_trend(st.session_state.current_audio_path, user_path) # Changed to get correlation
                    
                    # [è©•åˆ†é‚è¼¯ä¿®æ”¹]
                    # 1. æ–‡å­—æ­£ç¢ºåº¦ (75%)
                    base_score = score_text * 0.75
                    
                    # 2. èªèª¿ (25%)
                    # raw_pitch_score åœ¨åŸæœ¬çš„å‡½æ•¸ä¸­æ˜¯ 0-100ã€‚é€™è£¡æˆ‘å€‘æ”¹ç”¨ correlation ä¾†è¨ˆç®—ã€‚
                    # correlation ç¯„åœ -1 åˆ° 1
                    # å¦‚æœ correlation > 0, å‰‡ç‚ºæ­£ç›¸é—œã€‚åˆ†æ•¸ = correlation * 100 * 0.25 ?
                    # åŸæœ¬çš„ raw_pitch_score = max(0, correlation) * 100
                    
                    intonation_score = (raw_pitch_score / 100) * 25
                    
                    # 3. å€’æ‰£æ©Ÿåˆ¶ (è¶¨å‹¢ç›¸å)
                    penalty = 0
                    if correlation < -0.2: # è² ç›¸é—œï¼Œè¶¨å‹¢ç›¸å
                        penalty = 5
                    
                    final_score = base_score + intonation_score - penalty
                    final_score = max(0, min(100, final_score)) # ç¢ºä¿åœ¨ 0-100 ä¹‹é–“

                    # ä½¿ç”¨é¸æ“‡çš„æ¨¡å‹
                    # å‚³å…¥ correlation ä»¥ä¾› AI åˆ¤æ–·èªèª¿
                    feedback = get_ai_coach_feedback(google_api_key, selected_model, display_text, u_text, final_score, correlation)

                if final_score >= 80: st.success(f"ğŸ‰ åˆ†æ•¸ï¼š{final_score:.0f}")
                else: st.info(f"ğŸ’ª åˆ†æ•¸ï¼š{final_score:.0f}")
                
                st.write("ğŸ§ å›æ”¾è‡ªå·±ï¼š")
                st.audio(user_path, format="audio/wav")
                st.markdown(f'<div class="ai-feedback-box">{feedback}</div>', unsafe_allow_html=True)
                
                tab1, tab2 = st.tabs(["ğŸ”¤ ç³¾éŒ¯", "ğŸ“ˆ èªèª¿"])
                with tab1: st.markdown(f'<div class="diff-box">{diff_html}</div>', unsafe_allow_html=True)
                with tab2: 
                    if fig: st.pyplot(fig)
                    else: st.info("ç„¡æ³•åˆ†æèªèª¿")

# ==========================================
# æ¨¡å¼ B: æ‹¼å­—æ¸¬é©— (AIå‡ºé¡Œ)
# ==========================================
elif app_mode == "ğŸ“ æ‹¼å­—æ¸¬é©— (AIå‡ºé¡Œ)":
    vocab_list = load_vocab()
    st.subheader("ğŸ“ å–®å­—æœ¬æ‹¼å­—æ¸¬é©—")
    
    if not vocab_list:
        st.info("ğŸ“­ ç›®å‰å–®å­—åº«æ˜¯ç©ºçš„ã€‚è«‹å…ˆå»ã€Œè·Ÿè®€ç·´ç¿’ã€æŸ¥è©¢å–®å­—ä¸¦æŒ‰ã€Œâ­ æ”¶è—ã€ã€‚")
    else:
        st.write(f"ğŸ“š ç›®å‰ç´¯ç©å–®å­—ï¼š**{len(vocab_list)}** å€‹")
        st.caption("é»æ“Šä¸‹æ–¹æŒ‰éˆ•ï¼ŒAI æœƒå‡ºé¡Œè®“æ‚¨ç·´ç¿’ã€Œæ‹¼å­—ã€ï¼")
        
        c1, c2 = st.columns([1, 2])
        with c1:
            if st.button("ğŸ² AI éš¨æ©Ÿå‡ºä¸€é¡Œ", type="primary", use_container_width=True, disabled=not google_api_key):
                target = random.choice(vocab_list)
                word = target["word"]
                info = target["info"]

                with st.spinner(f"æ­£åœ¨ç‚º '{word}' å‡ºé¡Œä¸­..."):
                    # ä½¿ç”¨é¸æ“‡çš„æ¨¡å‹
                    q_text = generate_quiz(google_api_key, selected_model, word)
                    if q_text and "Q:" in q_text and "A:" in q_text:
                        st.session_state.quiz_data = {"word": word, "content": q_text, "original_info": info}
                        st.session_state.quiz_state = "QUESTION"
                        st.session_state.quiz_attempts = 0
                        st.session_state.quiz_last_msg = ""
                        st.session_state.quiz_error_counted = False
                        st.rerun()
                    else:
                        st.error(f"å‡ºé¡Œå¤±æ•—ï¼š{q_text}")
        
        if not google_api_key:
             st.warning("ğŸ‘‰ è«‹å…ˆè¼¸å…¥ API Keyï¼Œæ‰èƒ½ä½¿ç”¨ AI å‡ºé¡ŒåŠŸèƒ½ã€‚")

        if st.session_state.quiz_data:
            data = st.session_state.quiz_data
            
            if 'content' not in data:
                st.warning("âš ï¸ åµæ¸¬åˆ°æ¨¡å¼åˆ‡æ›ï¼Œè«‹é‡æ–°é»æ“Šä¸Šæ–¹ç´…è‰²æŒ‰éˆ•å‡ºé¡Œã€‚")
                st.session_state.quiz_data = None
                st.stop()
            
            content = data["content"]
            try:
                q_part = content.split("A:")[0].replace("Q:", "").strip()
            except:
                q_part = content
            
            st.markdown(f"""
            <div class="quiz-box">
                <h3>â“ å¡«ç©ºæ‹¼å­—ï¼š</h3>
                <p class="quiz-question">{q_part}</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.session_state.quiz_state == "RESULT":
                st.success(f"ğŸ‰ ç­”å°äº†ï¼ç­”æ¡ˆå°±æ˜¯ **{data['word']}**")
                
                # è‡ªå‹•ä¿®å¾©å–®å­—å¡
                if "å¾…æŸ¥è©¢" in data['original_info'] and google_api_key:
                    with st.spinner("ğŸ¤– æ­£åœ¨ç‚ºæ‚¨è‡ªå‹•è£œä¸Šå–®å­—å®šç¾©..."):
                        # ä½¿ç”¨é¸æ“‡çš„æ¨¡å‹
                        new_info = get_word_info(google_api_key, selected_model, data['word'], f"The word is {data['word']}")
                        if "æŸ¥è©¢å¤±æ•—" not in new_info:
                            data['original_info'] = new_info
                            add_word_to_vocab(data['word'], new_info)
                            st.toast("âœ¨ å–®å­—å¡å·²è‡ªå‹•ä¿®å¾©ï¼")

                try:
                    a_part = content.split("A:")[1].strip() if "A:" in content else "ç„¡ç¿»è­¯"
                except:
                    a_part = "è§£æéŒ¯èª¤"
                st.info(f"ğŸ’¡ ç¿»è­¯ï¼š{a_part}")

                st.markdown("---")
                st.caption("ğŸ“œ åŸå§‹å–®å­—å¡ï¼š")
                original_html = data['original_info'].replace('\n', '<br>')
                st.markdown(f'<div style="background-color:#fff9c4; padding:10px; border-radius:8px;">{original_html}</div>', unsafe_allow_html=True)

                w_path = speak_google(data['word'])
                if w_path: st.audio(w_path, format='audio/mp3')
                
                if st.button("ä¸‹ä¸€é¡Œ", use_container_width=True):
                    target = random.choice(vocab_list)
                    word = target["word"]
                    info = target["info"]
                    with st.spinner(f"æ­£åœ¨ç‚º '{word}' å‡ºé¡Œä¸­..."):
                        # ä½¿ç”¨é¸æ“‡çš„æ¨¡å‹
                        q_text = generate_quiz(google_api_key, selected_model, word)
                        if q_text and "Q:" in q_text and "A:" in q_text:
                            st.session_state.quiz_data = {"word": word, "content": q_text, "original_info": info}
                            st.session_state.quiz_state = "QUESTION"
                            st.session_state.quiz_attempts = 0
                            st.session_state.quiz_last_msg = ""
                            st.session_state.quiz_error_counted = False
                            st.rerun()

            else:
                user_spelling = st.text_input("âœï¸ è«‹è¼¸å…¥æ‚¨çš„ç­”æ¡ˆï¼š", key="spelling_input")
                
                c_sub, c_giveup = st.columns([2, 1])
                with c_sub:
                    if st.button("é€å‡ºæª¢æŸ¥", use_container_width=True):
                        correct_word = data['word'].strip().lower()
                        user_word = user_spelling.strip().lower()
                        
                        if correct_word == user_word:
                            st.balloons()
                            st.session_state.quiz_state = "RESULT"
                            st.rerun()
                        else:
                            st.session_state.quiz_attempts += 1
                            if not st.session_state.quiz_error_counted:
                                increment_error_count(data['word'])
                                st.session_state.quiz_error_counted = True
                            
                            hint = get_spelling_hint(data['word'], st.session_state.quiz_attempts)
                            st.session_state.quiz_last_msg = f"âŒ æ‹¼éŒ¯äº† (å˜—è©¦ {st.session_state.quiz_attempts} æ¬¡)<br>ğŸ’¡ æç¤ºï¼š{hint}"
                            st.rerun()
                
                with c_giveup:
                    if st.button("ğŸ³ï¸ æ”¾æ£„ï¼Œçœ‹ç­”æ¡ˆ", use_container_width=True):
                        if not st.session_state.quiz_error_counted:
                            increment_error_count(data['word'])
                            st.session_state.quiz_error_counted = True
                        st.session_state.quiz_state = "RESULT"
                        st.rerun()

                if st.session_state.quiz_last_msg:
                    st.markdown(f'<div class="hint-box">{st.session_state.quiz_last_msg}</div>', unsafe_allow_html=True)

# ==========================================
# æ¨¡å¼ C: è‹±è½æ‹¼å­—æ¸¬é©— (è‹±è½ä¿®å¾©ç‰ˆ)
# ==========================================
elif app_mode == "ğŸ‘‚ è‹±è½æ‹¼å­—æ¸¬é©—":
    vocab_list = load_vocab()
    st.subheader("ğŸ‘‚ å–®å­—æœ¬è‹±è½æ¸¬é©—")
    
    if not vocab_list:
        st.info("ğŸ“­ ç›®å‰å–®å­—åº«æ˜¯ç©ºçš„ã€‚è«‹å…ˆå»ã€Œè·Ÿè®€ç·´ç¿’ã€æŸ¥è©¢å–®å­—ä¸¦æŒ‰ã€Œâ­ æ”¶è—ã€ã€‚")
    else:
        st.write(f"ğŸ“š ç›®å‰ç´¯ç©å–®å­—ï¼š**{len(vocab_list)}** å€‹")
        st.caption("é»æ“Šä¸‹æ–¹æŒ‰éˆ•ï¼Œç³»çµ±æœƒæ’­æ”¾ç™¼éŸ³ï¼Œè«‹æ‚¨æ‹¼å‡ºå–®å­—ï¼")
        
        # [åŠŸèƒ½] éš¨æ©Ÿé¸å­—ä¸¦ç”¢ç”ŸéŸ³æª”
        if st.button("ğŸ§ æ’­æ”¾é¡Œç›® (éš¨æ©Ÿå–®å­—)", type="primary", use_container_width=True):
            target = random.choice(vocab_list)
            word = target["word"]
            info = target["info"]
            
            w_path = speak_google(word)
            if not w_path: w_path = speak_offline(word)
            
            st.session_state.quiz_data = {"word": word, "audio": w_path, "original_info": info}
            st.session_state.quiz_state = "QUESTION"
            st.session_state.quiz_attempts = 0
            st.session_state.quiz_last_msg = ""
            st.session_state.quiz_error_counted = False
            st.rerun()

        if st.session_state.quiz_data:
            data = st.session_state.quiz_data
            
            # [é›™é‡é˜²å‘†]
            if 'audio' not in data:
                st.warning("âš ï¸ åµæ¸¬åˆ°æ¨¡å¼åˆ‡æ›ï¼Œè«‹é‡æ–°é»æ“Šä¸Šæ–¹ç´…è‰²æŒ‰éˆ•æ’­æ”¾é¡Œç›®ã€‚")
                st.session_state.quiz_data = None
                st.stop()

            st.markdown("""
            <div class="quiz-box">
                <h3>ğŸ§ è«‹è½éŸ³æ‹¼å­—ï¼š</h3>
            </div>
            """, unsafe_allow_html=True)
            
            if 'audio' in data and data['audio']:
                st.audio(data['audio'], format='audio/mp3')
            else:
                st.error("ç„¡æ³•ç”ŸæˆèªéŸ³")

            if st.session_state.quiz_state == "RESULT":
                st.success(f"ğŸ‰ ç­”å°äº†ï¼ç­”æ¡ˆå°±æ˜¯ **{data['word']}**")
                
                # [è‡ªå‹•ä¿®å¾©] æª¢æŸ¥åŸå§‹å–®å­—å¡æ˜¯å¦ç‚º "å¾…æŸ¥è©¢"
                if "å¾…æŸ¥è©¢" in data['original_info'] and google_api_key:
                    with st.spinner("ğŸ¤– æ­£åœ¨ç‚ºæ‚¨è‡ªå‹•è£œä¸Šå–®å­—å®šç¾©..."):
                        # ä½¿ç”¨é¸æ“‡çš„æ¨¡å‹
                        new_info = get_word_info(google_api_key, selected_model, data['word'], f"The word is {data['word']}")
                        if "æŸ¥è©¢å¤±æ•—" not in new_info:
                            data['original_info'] = new_info
                            add_word_to_vocab(data['word'], new_info)
                            st.toast("âœ¨ å–®å­—å¡å·²è‡ªå‹•ä¿®å¾©ï¼")

                st.markdown("---")
                st.caption("ğŸ“œ åŸå§‹å–®å­—å¡ï¼š")
                original_html = data['original_info'].replace('\n', '<br>')
                st.markdown(f'<div style="background-color:#fff9c4; padding:10px; border-radius:8px;">{original_html}</div>', unsafe_allow_html=True)
                
                if st.button("ä¸‹ä¸€é¡Œ", use_container_width=True):
                    target = random.choice(vocab_list)
                    word = target["word"]
                    info = target["info"]
                    
                    w_path = speak_google(word)
                    if not w_path: w_path = speak_offline(word)
                    
                    st.session_state.quiz_data = {"word": word, "audio": w_path, "original_info": info}
                    st.session_state.quiz_state = "QUESTION"
                    st.session_state.quiz_attempts = 0
                    st.session_state.quiz_last_msg = ""
                    st.session_state.quiz_error_counted = False
                    st.rerun()
            else:
                user_spelling = st.text_input("âœï¸ è«‹è¼¸å…¥æ‚¨çš„ç­”æ¡ˆï¼š", key="listening_input")
                
                c_sub, c_giveup = st.columns([2, 1])
                with c_sub:
                    if st.button("é€å‡ºæª¢æŸ¥", use_container_width=True):
                        correct_word = data['word'].strip().lower()
                        user_word = user_spelling.strip().lower()
                        
                        if correct_word == user_word:
                            st.balloons()
                            st.session_state.quiz_state = "RESULT"
                            st.rerun()
                        else:
                            st.session_state.quiz_attempts += 1
                            if not st.session_state.quiz_error_counted:
                                increment_error_count(data['word'])
                                st.session_state.quiz_error_counted = True
                            
                            hint = get_spelling_hint(data['word'], st.session_state.quiz_attempts)
                            st.session_state.quiz_last_msg = f"âŒ æ‹¼éŒ¯äº† (å˜—è©¦ {st.session_state.quiz_attempts} æ¬¡)<br>ğŸ’¡ æç¤ºï¼š{hint}"
                            st.rerun()
                
                with c_giveup:
                    if st.button("ğŸ³ï¸ æ”¾æ£„ï¼Œçœ‹ç­”æ¡ˆ", use_container_width=True):
                        if not st.session_state.quiz_error_counted:
                            increment_error_count(data['word'])
                            st.session_state.quiz_error_counted = True
                        st.session_state.quiz_state = "RESULT"
                        st.rerun()

                if st.session_state.quiz_last_msg:
                    st.markdown(f'<div class="hint-box">{st.session_state.quiz_last_msg}</div>', unsafe_allow_html=True)

# ==========================================
# [ä¿®å¾©] æ¨¡å¼ D: âœï¸ å¥å‹æ”¹å¯«ç·´ç¿’
# ==========================================
elif app_mode == "âœï¸ å¥å‹æ”¹å¯«ç·´ç¿’":
    st.subheader("âœï¸ å¥å‹æ”¹å¯«ç·´ç¿’ (åš´æ ¼æ‹¼å­—ç‰ˆ)")
    st.info("AI æœƒéš¨æ©Ÿå‡ºé¡Œï¼Œè«‹ä¾æŒ‡ç¤ºæ”¹å¯«å¥å­ï¼ˆä¾‹å¦‚ï¼šè‚¯å®šå¥æ”¹å¦å®šå¥ï¼‰ã€‚")
    
    # è¼‰å…¥çµ±è¨ˆè³‡æ–™
    stats = load_grammar_stats()

    if not google_api_key:
        st.warning("ğŸ‘‰ è«‹å…ˆè¼¸å…¥ API Key æ‰èƒ½ä½¿ç”¨ AI å‡ºé¡Œã€‚")
    else:
        # å‡ºé¡Œå€
        if not st.session_state.grammar_queue:
            if st.button("ğŸ² AI éš¨æ©Ÿå‡ºé¡Œ (ä¸€æ¬¡ç”Ÿæˆ10é¡Œ)", type="primary", use_container_width=True):
                with st.spinner("ğŸ¤– æ­£åœ¨è¨­è¨ˆ 10 é“é¡Œç›®... (è«‹ç¨ç­‰ç´„ 3~5 ç§’)"):
                    data_list, err = generate_grammar_batch(google_api_key, selected_model, count=10)
                    if data_list:
                        st.session_state.grammar_queue = data_list
                        st.session_state.grammar_index = 0
                        st.session_state.grammar_feedback = ""
                        st.session_state.review_report = None # æ¸…ç©ºèˆŠå ±å‘Š
                        st.rerun()
                    else:
                        st.error(err)

        # ç­”é¡Œå€ (å¦‚æœæœ‰é¡Œç›®)
        if st.session_state.grammar_queue:
            # é€²åº¦æ¢
            current_q = st.session_state.grammar_index + 1
            total_q = len(st.session_state.grammar_queue)
            st.progress(current_q / total_q, text=f"é€²åº¦ï¼š{current_q} / {total_q}")
            
            # å–å‡ºç•¶å‰é¡Œç›®
            q = st.session_state.grammar_queue[st.session_state.grammar_index]

            st.markdown(f"""
            <div class="quiz-box">
                <p style="font-size: 20px; color: #555;">é¡Œç›®å¥å­ï¼š</p>
                <h3 style="color: #1b5e20;">{q['source']}</h3>
                <hr>
                <p style="font-size: 18px; font-weight: bold; color: #d84315;">ğŸ‘‰ ä»»å‹™ï¼š{q['task']}</p>
            </div>
            """, unsafe_allow_html=True)

            user_input = st.text_input("âœï¸ è«‹è¼¸å…¥æ‚¨çš„ç­”æ¡ˆï¼š", key=f"grammar_input_{st.session_state.grammar_index}")

            # æª¢æŸ¥æŒ‰éˆ•
            if st.button("é€å‡ºæª¢æŸ¥", use_container_width=True, key=f"check_btn_{st.session_state.grammar_index}"):
                if user_input.strip():
                    with st.spinner("ğŸ¤– AI è€å¸«æ­£åœ¨æ‰¹æ”¹ (åš´æ ¼æ‹¼å­—æ¨¡å¼)..."):
                        is_correct, feedback = check_grammar_answer(
                            google_api_key, 
                            selected_model, 
                            f"å°‡ '{q['source']}' æ”¹å¯«ç‚º {q['task']}", 
                            user_input, 
                            q['answer']
                        )
                        st.session_state.grammar_feedback = (is_correct, feedback)
                        
                        # [æ›´æ–°çµ±è¨ˆ] (åŒ…å«è©³ç´°éŒ¯èª¤æ—¥èªŒ)
                        topic_name = q.get('topic', q.get('task', 'Unknown'))
                        update_grammar_stats(topic_name, is_correct, q['source'], user_input, q['answer'], feedback)
                else:
                    st.warning("è«‹å…ˆè¼¸å…¥ç­”æ¡ˆå–”ï¼")

            # é¡¯ç¤ºå›é¥‹èˆ‡ä¸‹ä¸€é¡ŒæŒ‰éˆ•
            if st.session_state.grammar_feedback:
                is_correct, feedback_text = st.session_state.grammar_feedback
                
                if is_correct:
                    st.markdown(f'<div class="ai-feedback-box" style="border-left: 5px solid #4caf50; background-color: #e8f5e9;">ğŸ‰ æ­£ç¢ºï¼<br>{feedback_text}</div>', unsafe_allow_html=True)
                else:
                    st.markdown(f'<div class="ai-feedback-box" style="border-left: 5px solid #f44336; background-color: #ffebee;">âŒ éŒ¯èª¤<br>{feedback_text}</div>', unsafe_allow_html=True)
                
                with st.expander("ğŸ‘€ æŸ¥çœ‹åƒè€ƒç­”æ¡ˆ"):
                    st.info(f"åƒè€ƒç­”æ¡ˆï¼š{q['answer']}")
                
                st.markdown("---")
                # åˆ¤æ–·æ˜¯å¦é‚„æœ‰ä¸‹ä¸€é¡Œ
                if current_q < total_q:
                    if st.button("ä¸‹ä¸€é¡Œ â¡ï¸", type="primary", use_container_width=True):
                        st.session_state.grammar_index += 1
                        st.session_state.grammar_feedback = ""
                        st.rerun()
                else:
                    if st.button("ğŸ å®Œæˆï¼å†ä¾†ä¸€çµ„ (10é¡Œ)", type="primary", use_container_width=True):
                        st.session_state.grammar_queue = [] # æ¸…ç©ºä»¥é‡æ–°ç”Ÿæˆ
                        st.session_state.grammar_index = 0
                        st.session_state.grammar_feedback = ""
                        st.session_state.review_report = None # é‡ç½®å ±å‘Š
                        st.rerun()

    # [æ–°å¢] å¼±é»åˆ†æå ±è¡¨ (å«è©³ç´°æ—¥èªŒ)
    st.markdown("---")
    with st.expander("ğŸ“Š æ‚¨çš„æ–‡æ³•å¼±é»åˆ†æ", expanded=True):
        if stats:
            # è½‰æ›ç‚º DataFrame
            data = []
            for topic, s in stats.items():
                accuracy = (s['correct'] / s['total']) * 100 if s['total'] > 0 else 0
                data.append({"é¡Œå‹": topic, "ç·´ç¿’é¡Œæ•¸": s['total'], "æ­£ç¢ºæ•¸": s['correct'], "æ­£ç¢ºç‡": f"{accuracy:.1f}%", "raw_acc": accuracy})
            
            df_stats = pd.DataFrame(data)
            # ä¾ç…§æ­£ç¢ºç‡ç”±ä½åˆ°é«˜æ’åº (æ‰¾å‡ºå¼±é»)
            df_stats = df_stats.sort_values(by="raw_acc", ascending=True)
            
            st.dataframe(
                df_stats[["é¡Œå‹", "æ­£ç¢ºç‡", "ç·´ç¿’é¡Œæ•¸", "æ­£ç¢ºæ•¸"]], 
                use_container_width=True, 
                hide_index=True
            )
            
            # [æ–°å¢] AI ç¶œåˆæª¢è¨å ±å‘ŠæŒ‰éˆ•
            if st.button("ğŸ“‘ ç”Ÿæˆ AI ç¶œåˆæª¢è¨å ±å‘Š (åˆ†ææ­·å²éŒ¯èª¤)", type="secondary"):
                with st.spinner("ğŸ§  AI é¡§å•æ­£åœ¨åˆ†ææ‰€æœ‰æ­·å²éŒ¯èª¤ï¼Œè«‹ç¨å€™..."):
                    report_text = generate_review_report(google_api_key, selected_model, stats)
                    st.session_state.review_report = report_text
            
            if st.session_state.review_report:
                st.markdown("### ğŸ“ AI æª¢è¨å ±å‘Š")
                st.markdown(st.session_state.review_report)
                
            # [æ–°å¢] è©³ç´°éŒ¯èª¤è¿½è¹¤æ—¥èªŒ (å¯å±•é–‹)
            st.markdown("### ğŸ•µï¸â€â™€ï¸ è©³ç´°éŒ¯èª¤è¿½è¹¤æ—¥èªŒ")
            for topic, s in stats.items():
                if "errors" in s and s["errors"]:
                    with st.expander(f"âŒ {topic} ({len(s['errors'])} ç­†éŒ¯èª¤)"):
                        for err in reversed(s["errors"]): # æœ€æ–°éŒ¯èª¤åœ¨æœ€ä¸Šé¢
                            st.markdown(f"""
                            **æ™‚é–“**: {err.get('time', 'N/A')}
                            - **é¡Œç›®**: {err.get('q', 'N/A')}
                            - **æ‚¨çš„å›ç­”**: `{err.get('user', 'N/A')}`
                            - **æ­£ç¢ºç­”æ¡ˆ**: `{err.get('ans', 'N/A')}`
                            - **AI é»è©•**: {err.get('feedback', 'N/A')}
                            ---
                            """)
        else:
            st.info("ç›®å‰é‚„æ²’æœ‰ç·´ç¿’è¨˜éŒ„ï¼Œå¿«é–‹å§‹ç·´ç¿’å§ï¼")

# ==========================================
# [æ–°å¢] æ¨¡å¼ E: çœ‹å­—ç™¼éŸ³æŒ‘æˆ°
# ==========================================
elif app_mode == "ğŸ—£ï¸ çœ‹å­—ç™¼éŸ³æŒ‘æˆ°":
    st.subheader("ğŸ—£ï¸ çœ‹å­—ç™¼éŸ³æŒ‘æˆ° (AI éš¨æ©Ÿå‡ºé¡Œ)")
    st.info("è«‹çœ‹å–®å­—ä¸¦å”¸å‡ºä¾†ï¼ŒAI è€å¸«æœƒåš´æ ¼æª¢æŸ¥æ‚¨çš„ç™¼éŸ³ï¼(70% å¤šéŸ³ç¯€ / 30% å–®éŸ³ç¯€)")
    
    if not google_api_key:
        st.warning("ğŸ“­ è«‹å…ˆè¼¸å…¥ API Key æ‰èƒ½ä½¿ç”¨ AI å‡ºé¡Œã€‚")
    else:
        # å‡ºé¡ŒæŒ‰éˆ•
        if not st.session_state.pronounce_data:
            if st.button("ğŸ² é–‹å§‹æŒ‘æˆ° (AI éš¨æ©Ÿå‡ºé¡Œ)", type="primary", use_container_width=True):
                with st.spinner("ğŸ¤– AI æ­£åœ¨æ€è€ƒé¡Œç›®..."):
                    word = generate_random_word_ai(google_api_key, selected_model)
                    st.session_state.pronounce_data = {"word": word}
                    st.session_state.pronounce_attempts = 0
                    st.session_state.pronounce_feedback = ""
                    st.session_state.pronounce_rec_key += 1 # é‡ç½®éŒ„éŸ³
                    st.rerun()
        
        # é¡¯ç¤ºé¡Œç›®å€
        if st.session_state.pronounce_data:
            word = st.session_state.pronounce_data["word"]
            
            # é¡¯ç¤ºå–®å­—
            st.markdown(f"""
            <div class="quiz-box">
                <p style="color: #555;">è«‹å”¸å‡ºé€™å€‹å–®å­—ï¼š</p>
                <h1 style="font-size: 60px; color: #d84315; margin: 20px 0;">{word}</h1>
            </div>
            """, unsafe_allow_html=True)
            
            # éŒ„éŸ³å€
            user_audio = st.audio_input("è«‹æŒ‰éŒ„éŸ³éˆ•ä¸¦å”¸å‡ºå–®å­—", key=f"pronounce_rec_{st.session_state.pronounce_rec_key}")
            
            if user_audio and google_api_key:
                with st.spinner("ğŸ‘‚ AI è€å¸«æ­£åœ¨è†è½ä¸¦åˆ†æ..."):
                    # è½‰éŒ„ (ä½¿ç”¨ UUID é¿å…ç·©å­˜)
                    unique_filename = f"user_input_{uuid.uuid4()}.wav"
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(user_audio.read()); user_path = tmp.name
                    
                    u_text = transcribe_audio(user_path)
                    
                    if not u_text:
                        st.error("âš ï¸ ç„¡æ³•è¾¨è­˜èªéŸ³ï¼Œè«‹å†è©¦ä¸€æ¬¡ (å¯èƒ½æ˜¯éº¥å…‹é¢¨å•é¡Œæˆ–ç’°å¢ƒå¤ªåµ)ã€‚")
                    else:
                        st.write(f"ğŸ“ è¾¨è­˜çµæœï¼š**{u_text}**")
                        
                        # åˆ¤æ–·çµæœ (å­—ä¸²æ¯”å° + AI åˆ¤å®š)
                        if u_text.lower().strip() == word.lower().strip():
                             st.balloons()
                             st.success("ğŸ‰ ç™¼éŸ³æ­£ç¢ºï¼å¤ªæ£’äº†ï¼")
                             st.session_state.pronounce_feedback = "âœ… ç™¼éŸ³æ¨™æº–ï¼"
                             
                             # ä¸‹ä¸€é¡ŒæŒ‰éˆ• (ç›´æ¥å‡ºé¡Œ)
                             if st.button("ä¸‹ä¸€é¡Œ â¡ï¸", type="primary", use_container_width=True):
                                 with st.spinner("ğŸ¤– AI æ­£åœ¨å‡ºä¸‹ä¸€é¡Œ..."):
                                     word = generate_random_word_ai(google_api_key, selected_model)
                                     st.session_state.pronounce_data = {"word": word}
                                     st.session_state.pronounce_attempts = 0
                                     st.session_state.pronounce_feedback = ""
                                     st.session_state.pronounce_rec_key += 1
                                     st.rerun()
                        else:
                            # ç™¼éŸ³éŒ¯èª¤è™•ç†
                            st.session_state.pronounce_attempts += 1
                            increment_pronunciation_error(word) # è¨˜éŒ„éŒ¯èª¤
                            
                            # è«‹æ±‚ AI æ•™å­¸
                            feedback = get_pronunciation_feedback(google_api_key, selected_model, word, u_text)
                            st.session_state.pronounce_feedback = feedback
                            
                            if st.session_state.pronounce_attempts >= 5:
                                st.error("ğŸ³ï¸ æŒ‘æˆ°å¤±æ•— (å·²é” 5 æ¬¡)ï¼è«‹çœ‹ä¸‹æ–¹è©³è§£ä¸¦ç·´ç¿’ã€‚")
                                # å¼·åˆ¶é¡¯ç¤ºä¸‹ä¸€é¡ŒæŒ‰éˆ•
                                if st.button("ä¸‹ä¸€é¡Œ â¡ï¸", type="primary", use_container_width=True):
                                     with st.spinner("ğŸ¤– AI æ­£åœ¨å‡ºä¸‹ä¸€é¡Œ..."):
                                         word = generate_random_word_ai(google_api_key, selected_model)
                                         st.session_state.pronounce_data = {"word": word}
                                         st.session_state.pronounce_attempts = 0
                                         st.session_state.pronounce_feedback = ""
                                         st.session_state.pronounce_rec_key += 1
                                         st.rerun()
                            else:
                                st.warning(f"âŒ ç™¼éŸ³å°šéœ€åŠ å¼· (å‰©é¤˜æ©Ÿæœƒï¼š{5 - st.session_state.pronounce_attempts} æ¬¡)")
            
            # é¡¯ç¤º AI å›é¥‹
            if st.session_state.pronounce_feedback:
                st.markdown(f'<div class="ai-feedback-box">{st.session_state.pronounce_feedback}</div>', unsafe_allow_html=True)
                
                # è½æ­£ç¢ºç™¼éŸ³
                if st.button("ğŸ”Š è½è€å¸«ç¤ºç¯„ç™¼éŸ³"):
                    w_path = speak_google(word)
                    if not w_path: w_path = speak_offline(word)
                    st.audio(w_path, format='audio/mp3')

            # æ”¾æ£„æŒ‰éˆ•
            if st.button("ğŸ³ï¸ æ”¾æ£„ï¼Œæ›ä¸‹ä¸€é¡Œ", type="secondary"):
                 increment_pronunciation_error(word)
                 with st.spinner("ğŸ¤– AI æ­£åœ¨å‡ºä¸‹ä¸€é¡Œ..."):
                    word = generate_random_word_ai(google_api_key, selected_model)
                    st.session_state.pronounce_data = {"word": word}
                    st.session_state.pronounce_attempts = 0
                    st.session_state.pronounce_feedback = ""
                    st.session_state.pronounce_rec_key += 1
                    st.rerun()

    # [æ–°å¢] ç™¼éŸ³å¼±é»åˆ†æå ±å‘Š
    st.markdown("---")
    with st.expander("ğŸ“Š ç™¼éŸ³å¼±é»åˆ†æå ±å‘Š", expanded=True):
        vocab_list = load_vocab() # è¼‰å…¥å–®å­—åº«æª¢æŸ¥éŒ¯èª¤
        error_list = [v for v in vocab_list if v.get("pronunciation_errors", 0) > 0]
        error_list.sort(key=lambda x: x["pronunciation_errors"], reverse=True)
        
        if error_list:
            st.write("#### ğŸš¨ å¸¸å”¸éŒ¯å–®å­— Top 5")
            for i, v in enumerate(error_list[:5]): 
                 st.write(f"**{i+1}. {v['word']}** (éŒ¯ {v['pronunciation_errors']} æ¬¡)")
            
            if st.button("ğŸ“‘ ç”Ÿæˆç™¼éŸ³è¨ºæ–·å ±å‘Š", type="primary"):
                with st.spinner("ğŸ§  AI èªéŸ³æ²»ç™‚å¸«æ­£åœ¨åˆ†ææ‚¨çš„ç™¼éŸ³ç¿’æ…£..."):
                    report = generate_pronunciation_report(google_api_key, selected_model, error_list)
                    st.session_state.pronounce_report = report
            
            if st.session_state.pronounce_report:
                st.markdown(st.session_state.pronounce_report)
        else:
            st.info("ç›®å‰ç™¼éŸ³ç´€éŒ„è‰¯å¥½ï¼Œç¹¼çºŒä¿æŒï¼")

# ==========================================
# [æ–°å¢] æ¨¡å¼ G: ğŸ¤– AI è‡ªå‹•ç”ŸæˆçŸ­æ–‡è·Ÿè®€
# ==========================================
elif app_mode == "ğŸ¤– AI è‡ªå‹•ç”ŸæˆçŸ­æ–‡è·Ÿè®€":
    st.subheader("ğŸ¤– AI è‡ªå‹•ç”ŸæˆçŸ­æ–‡è·Ÿè®€")
    
    # æª¢æŸ¥ API Key
    if not google_api_key:
         st.warning("ğŸ‘‰ è«‹å…ˆåœ¨å´é‚Šæ¬„è¼¸å…¥ API Keyï¼Œæ‰èƒ½ä½¿ç”¨ AI ç”ŸæˆåŠŸèƒ½ã€‚")
    else:
        # --- è¨­å®šéšæ®µ (Setup Phase) ---
        if not st.session_state.game_active:
            vocab_list = load_vocab()
            if not vocab_list:
                st.warning("ğŸ“­ æ‚¨çš„å–®å­—åº«ç›®å‰æ˜¯ç©ºçš„ï¼Œç„¡æ³•ç”Ÿæˆæ–‡ç« ã€‚è«‹å…ˆå»ã€ŒğŸ“– è·Ÿè®€ç·´ç¿’ã€åŠ å…¥å–®å­—ï¼")
            else:
                st.info(f"ğŸ“š ç›®å‰å–®å­—åº«å…±æœ‰ {len(vocab_list)} å€‹å–®å­—ã€‚")
                
                # è¨­å®šé¸é …
                col1, col2 = st.columns(2)
                with col1:
                    word_count = st.slider("æ–‡ç« é•·åº¦ (å­—æ•¸)", 30, 200, 50, step=10)
                
                if st.button("ğŸš€ ç”ŸæˆçŸ­æ–‡ä¸¦é–‹å§‹ç·´ç¿’", type="primary", use_container_width=True):
                    with st.spinner("ğŸ¤– AI æ­£åœ¨æ’°å¯«å°ˆå±¬çŸ­æ–‡..."):
                        generated_story = generate_story_from_vocab(google_api_key, selected_model, vocab_list, word_count)
                        
                        if "Error" in generated_story:
                            st.error(generated_story)
                        else:
                            # æˆåŠŸç”Ÿæˆï¼Œåˆ‡æ›åˆ°è·Ÿè®€æ¨¡å¼
                            s = split_text_smartly(generated_story)
                            if s: 
                                st.session_state.sentences = s
                                st.session_state.current_index = 0
                                st.session_state.game_active = True
                                st.session_state.is_finished = False
                                st.session_state.start_time = time.time()
                                st.session_state.segment_times = {}
                                st.session_state.full_text_explanation = None # æ–°çŸ­æ–‡æ¸…ç©ºè¬›è§£
                                st.rerun()
                            else:
                                st.error("ç”Ÿæˆçš„æ–‡ç« ç„¡æ³•åˆ†æ®µï¼Œè«‹é‡è©¦ã€‚")

        # --- ç·´ç¿’éšæ®µ (Practice Phase) ---
        # é€™éƒ¨åˆ†å®Œå…¨è¤‡è£½ Mode A çš„é‚è¼¯ï¼Œä½†ç‚ºäº†é¿å…è®Šæ•¸è¡çªï¼Œç›´æ¥ä½¿ç”¨ session_state
        else:
            if st.session_state.is_finished:
                st.balloons()
                st.markdown("""
                <div class="backup-alert">
                    <h2>ğŸ‰ ç·´ç¿’çµæŸï¼</h2>
                    <p>æ‚¨å·²å®Œæˆé€™ç¯‡ AI ç”Ÿæˆçš„çŸ­æ–‡ç·´ç¿’ã€‚</p>
                </div>
                """, unsafe_allow_html=True)
                
                if st.session_state.segment_times:
                    max_time_idx = max(st.session_state.segment_times, key=st.session_state.segment_times.get)
                    max_time_val = st.session_state.segment_times[max_time_idx]
                    st.info(f"ğŸ’¡ åˆ†æï¼šæ‚¨åœ¨ç¬¬ {max_time_idx+1} æ®µèŠ±äº†æœ€å¤šæ™‚é–“ ({max_time_val:.1f}ç§’)ã€‚")

                if st.button("ğŸ”„ å†ç”Ÿæˆä¸€ç¯‡ / å›åˆ°è¨­å®šé "):
                    st.session_state.game_active = False
                    st.session_state.is_finished = False
                    st.session_state.segment_times = {}
                    st.rerun()
                st.stop()

            idx = st.session_state.current_index
            sentences = st.session_state.sentences
            target_sentence = sentences[idx]

            # ç¿»é é‚è¼¯ (è¤‡è£½è‡ª Mode A)
            def switch_page_g(increment):
                end_time = time.time()
                duration = end_time - st.session_state.start_time
                if idx in st.session_state.segment_times:
                    st.session_state.segment_times[idx] += duration
                else:
                    st.session_state.segment_times[idx] = duration
                st.session_state.current_index += increment
                st.session_state.current_audio_path = None
                st.session_state.start_time = time.time()
                st.rerun()

            c1, c2, c3 = st.columns([1, 4, 1])
            with c1: 
                if st.button("â¬…ï¸ ä¸Šå¥", disabled=(idx==0), use_container_width=True, key="g_prev"):
                    switch_page_g(-1)
            with c2: st.progress((idx+1)/len(sentences), text=f"é€²åº¦ï¼š{idx+1} / {len(sentences)}")
            with c3:
                is_last = (idx == len(sentences) - 1)
                btn_text = "å®Œæˆ ğŸ‰" if is_last else "ä¸‹å¥ â¡ï¸"
                if st.button(btn_text, use_container_width=True, key="g_next"):
                    if is_last:
                        switch_page_g(0) 
                        st.session_state.is_finished = True
                        st.rerun()
                    else:
                        switch_page_g(1)
            
            if st.button("ğŸ ä¸­é€”çµæŸ", type="secondary", use_container_width=True, key="g_stop"):
                 st.session_state.is_finished = True
                 st.rerun()

            col_L, col_R = st.columns([1.5, 1], gap="large")

            with col_L:
                st.subheader("ğŸ“– é–±è®€")
                if "Full Text Review" in target_sentence:
                    st.info("ğŸŒŸ æŒ‘æˆ°æ™‚é–“ï¼šå…¨æ–‡é€£è®€ï¼")
                
                display_text = target_sentence.replace("ğŸŒŸ Full Text Review: ", "")
                st.markdown(f'<div class="reading-box">{display_text}</div>', unsafe_allow_html=True)
                
                # [æ–°å¢åŠŸèƒ½] é‡å°å…¨æ–‡é€£è®€å€å¡Šçš„ AI è€å¸«è¬›è§£åŠŸèƒ½ + å„²å­˜
                if "Full Text Review" in target_sentence:
                    st.markdown("---")
                    c_ai, c_save = st.columns([2, 1])
                    
                    with c_ai:
                        if st.button("ğŸ‘©â€ğŸ« è«‹ AI è€å¸«ç¿»è­¯ä¸¦è¬›è§£é‡é» (åˆå­¸è€…æ¨¡å¼)", key="g_full_text_explain_btn"):
                            with st.spinner("ğŸ‘©â€ğŸ« AI è€å¸«æ­£åœ¨åˆ†ææ¶æ§‹ã€å¥å‹èˆ‡æ–‡æ³•ï¼Œè«‹ç¨å€™..."):
                                explanation = get_ai_text_explanation(google_api_key, selected_model, display_text)
                                st.session_state.full_text_explanation = explanation
                                st.success("åˆ†æå®Œæˆï¼")
                    
                    with c_save:
                        # [ä¿®æ”¹] å„²å­˜æ™‚åŒæ™‚å‚³å…¥ explanation
                        if st.button("ğŸ’¾ å„²å­˜é€™ç¯‡çŸ­æ–‡ (å«ç­†è¨˜)", type="secondary", key="g_save_story_btn"):
                            result = save_story_to_disk(display_text, st.session_state.full_text_explanation)
                            if result == "UPDATED": st.toast("âœ… å·²æ›´æ–°ç­†è¨˜åˆ°ç¾æœ‰å­˜æª”ï¼")
                            elif result: st.toast("âœ… çŸ­æ–‡èˆ‡ç­†è¨˜å·²å„²å­˜ï¼")
                            else: st.toast("âš ï¸ å·²ç¶“å­˜éå›‰ï¼")
                    
                    # é¡¯ç¤º AI è¬›è§£ (æŒçºŒå­˜åœ¨)
                    if st.session_state.full_text_explanation:
                        st.markdown("---")
                        # é¡¯ç¤ºå¤§å­—é«”åŸæ–‡
                        st.markdown(f'<div class="story-text-large">{display_text}</div>', unsafe_allow_html=True)
                        st.markdown(st.session_state.full_text_explanation)

                    st.markdown("---")

                # å–®å­—æŸ¥è©¢ (è¤‡è£½è‡ª Mode A)
                st.caption("ğŸ‘‡ é»æ“ŠæŸ¥å–®å­— (éœ€è¼¸å…¥ API Key)ï¼š")
                words = re.findall(r"\b\w+\b", display_text)
                cols = st.columns(5)
                for i, word in enumerate(words):
                    if cols[i % 5].button(word, key=f"wg_{idx}_{i}", disabled=not google_api_key):
                        st.session_state.current_word_target = word
                        with st.spinner("ğŸ” AI æŸ¥è©¢ä¸­..."):
                            info = get_word_info(google_api_key, selected_model, word, display_text)
                            st.session_state.current_word_info = info
                            if "æŸ¥è©¢å¤±æ•—" not in info and "è«‹è¼¸å…¥ API Key" not in info:
                                w_path = speak_google(word, 1.0)
                                if not w_path: w_path = speak_offline(word, 1.0)
                                st.session_state.current_word_audio = w_path
                            else:
                                st.session_state.current_word_audio = None
                
                if st.session_state.current_word_info:
                    info_html = st.session_state.current_word_info.replace('\n', '<br>')
                    st.markdown(f'<div class="definition-card">{info_html}</div>', unsafe_allow_html=True)
                    
                    c_p, c_s = st.columns([4, 1])
                    with c_p:
                        if st.session_state.current_word_audio:
                            st.audio(st.session_state.current_word_audio, format='audio/mp3')
                    with c_s:
                        if "æŸ¥è©¢å¤±æ•—" not in st.session_state.current_word_info:
                            if st.button("â­ æ”¶è—", use_container_width=True, type="primary", key="g_save"):
                                saved = add_word_to_vocab(st.session_state.current_word_target, st.session_state.current_word_info)
                                if saved: st.toast("âœ… å·²æˆåŠŸæ”¶è—ï¼")
                                else: st.toast("âš ï¸ å–®å­—åº«è£¡å·²ç¶“æœ‰å›‰ï¼")

                st.markdown("---")
                st.subheader("ğŸ—£ï¸ ç¤ºç¯„")
                if st.session_state.current_audio_path is None:
                    path = None
                    if "ç·šä¸Š" in tts_mode: path = speak_google(display_text, voice_speed)
                    if not path: path = speak_offline(display_text, voice_speed)
                    st.session_state.current_audio_path = path

                if st.session_state.current_audio_path:
                    st.audio(st.session_state.current_audio_path, format="audio/mp3")
                else:
                    st.warning("ç„¡æ³•ç”ŸæˆèªéŸ³")

            with col_R:
                st.subheader("ğŸ™ï¸ å£èªª")
                st.markdown(f'<div class="mobile-hint-card" style="white-space: pre-wrap;">ğŸ“– è·Ÿè®€ï¼š<br>{display_text}</div>', unsafe_allow_html=True)
                
                user_audio = st.audio_input("éŒ„éŸ³", key=f"rec_g_{idx}", disabled=not google_api_key)
                
                if user_audio and st.session_state.current_audio_path and google_api_key:
                    with st.spinner("ğŸ¤– AI åˆ†æä¸­..."):
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                            tmp.write(user_audio.read()); user_path = tmp.name
                        
                        u_text = transcribe_audio(user_path)
                        # [ä¿®æ”¹] è©•åˆ†é‚è¼¯
                        score_text, diff_html = check_similarity_visual(display_text, u_text)
                        fig, raw_pitch_score, correlation = plot_and_get_trend(st.session_state.current_audio_path, user_path) # ä½¿ç”¨ correlation
                        
                        # 1. æ–‡å­—åˆ†æ•¸ (75%)
                        base_score = score_text * 0.75
                        
                        # 2. èªèª¿åˆ†æ•¸ (25%) - correlation > 0.5 çµ¦æ»¿åˆ†
                        intonation_score = 0
                        pitch_status = "å¹³æ·¡"
                        if correlation > 0.5: 
                            intonation_score = 25
                            pitch_status = "è‡ªç„¶æµæš¢"
                        elif correlation > 0:
                            intonation_score = correlation * 50 # 0.5 -> 25
                            pitch_status = "å°šå¯"
                        else:
                            pitch_status = "å¹³æ·¡æˆ–ç›¸å"
                        
                        # 3. å€’æ‰£æ©Ÿåˆ¶
                        penalty = 0
                        if correlation < -0.2: 
                            penalty = 5
                            pitch_status = "âš ï¸ èªèª¿å‡é™ç›¸å (æ‰£5åˆ†)"
                        
                        final_score = base_score + intonation_score - penalty
                        final_score = max(0, min(100, final_score))
                        
                        feedback = get_ai_coach_feedback(google_api_key, selected_model, display_text, u_text, final_score, pitch_status)

                    if final_score >= 80: st.success(f"ğŸ‰ åˆ†æ•¸ï¼š{final_score:.0f}")
                    else: st.info(f"ğŸ’ª åˆ†æ•¸ï¼š{final_score:.0f}")
                    
                    st.write("ğŸ§ å›æ”¾è‡ªå·±ï¼š")
                    st.audio(user_path, format="audio/wav")
                    st.markdown(f'<div class="ai-feedback-box">{feedback}</div>', unsafe_allow_html=True)
                    
                    tab1, tab2 = st.tabs(["ğŸ”¤ ç³¾éŒ¯", "ğŸ“ˆ èªèª¿"])
                    with tab1: st.markdown(f'<div class="diff-box">{diff_html}</div>', unsafe_allow_html=True)
                    with tab2: 
                        if fig: st.pyplot(fig)
                        else: st.info("ç„¡æ³•åˆ†æèªèª¿")

# ==========================================
# æ¨¡å¼ F: å–®å­—åº«æª¢è¦–
# ==========================================
elif app_mode == "ğŸ“š å–®å­—åº«æª¢è¦–":
    st.subheader("ğŸ“š å®Œæ•´å–®å­—åº«åˆ—è¡¨")
    vocab_list = load_vocab()
    
    if vocab_list:
        df = pd.DataFrame(vocab_list)
        if "error_count" not in df.columns: df["error_count"] = 0
        if "pronunciation_errors" not in df.columns: df["pronunciation_errors"] = 0
        if "info" not in df.columns: df["info"] = ""
        
        df_display = df[["word", "error_count", "pronunciation_errors", "info"]].rename(columns={
            "word": "å–®å­—",
            "error_count": "æ‹¼å­—éŒ¯èª¤",
            "pronunciation_errors": "ç™¼éŸ³éŒ¯èª¤",
            "info": "è©³ç´°å®šç¾©"
        })
        
        # [æ’åºé¸æ“‡]
        sort_option = st.radio("æ’åºæ–¹å¼ï¼š", ["ğŸ”¥ æ‹¼å­—éŒ¯èª¤æ¬¡æ•¸", "ğŸ—£ï¸ ç™¼éŸ³éŒ¯èª¤æ¬¡æ•¸", "ğŸ”¤ å­—æ¯é †åº"], horizontal=True)
        
        if sort_option == "ğŸ”¥ æ‹¼å­—éŒ¯èª¤æ¬¡æ•¸":
            df_display = df_display.sort_values(by="æ‹¼å­—éŒ¯èª¤", ascending=False)
        elif sort_option == "ğŸ—£ï¸ ç™¼éŸ³éŒ¯èª¤æ¬¡æ•¸":
             df_display = df_display.sort_values(by="ç™¼éŸ³éŒ¯èª¤", ascending=False)
        else:
            df_display = df_display.sort_values(by="å–®å­—", ascending=True)
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ç¸½å–®å­—æ•¸", len(vocab_list))
        col2.metric("æ‹¼å­—éœ€åŠ å¼·", len(df[df["error_count"] > 0]))
        col3.metric("ç™¼éŸ³éœ€åŠ å¼·", len(df[df["pronunciation_errors"] > 0]))
        
        st.dataframe(df_display, use_container_width=True, height=600, hide_index=True)
    else:
        st.info("ğŸ“­ ç›®å‰å–®å­—åº«æ˜¯ç©ºçš„ï¼Œè«‹å…ˆå»ã€Œè·Ÿè®€ç·´ç¿’ã€åŠ å…¥å–®å­—ï¼")