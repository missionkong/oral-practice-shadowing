import streamlit as st
import json
import random
import os
import difflib
import re
import tempfile
import numpy as np
import matplotlib.pyplot as plt
import speech_recognition as sr
from gtts import gTTS
import ssl

# [æ ¸å¿ƒä¿®æ”¹] æ”¹ç”¨ Vertex AI
import vertexai
from vertexai.preview.generative_models import GenerativeModel

# 1. è¨­å®šé é¢
try:
    st.set_page_config(page_title="AI è‹±æ–‡æ•™ç·´ Pro (Vertex æœ¬æ©Ÿé©—è­‰ç‰ˆ)", layout="wide", page_icon="ğŸ“")
except:
    pass

# 2. å¿½ç•¥ SSL éŒ¯èª¤
ssl._create_default_https_context = ssl._create_unverified_context

# 3. å®‰å…¨åŒ¯å…¥
HAS_OFFLINE_TTS = False
try:
    import pyttsx3
    HAS_OFFLINE_TTS = True
except ImportError:
    HAS_OFFLINE_TTS = False

try:
    import librosa
    HAS_LIBROSA = True
except ImportError:
    HAS_LIBROSA = False

# ==========================================
# 0. è³‡æ–™å­˜å–é‚è¼¯
# ==========================================
VOCAB_FILE = "vocab_book.json"
PROJECT_FILE = "google_project_id.txt"

def load_vocab():
    if not os.path.exists(VOCAB_FILE): return []
    try:
        with open(VOCAB_FILE, "r", encoding="utf-8") as f: return json.load(f)
    except: return []

def save_vocab_to_disk(vocab_list):
    with open(VOCAB_FILE, "w", encoding="utf-8") as f:
        json.dump(vocab_list, f, ensure_ascii=False, indent=4)

def add_word_to_vocab(word, info):
    if not word or "æŸ¥è©¢å¤±æ•—" in info or "è«‹æª¢æŸ¥" in info: return False
    vocab_list = load_vocab()
    for v in vocab_list:
        if v["word"] == word: return False
    vocab_list.append({"word": word, "info": info})
    save_vocab_to_disk(vocab_list)
    return True

# ==========================================
# [æ ¸å¿ƒä¿®æ”¹] Vertex AI åˆå§‹åŒ– (é—œéµï¼šè®€å–ä¸Šå‚³çš„æª”æ¡ˆ)
# ==========================================
def init_vertex_ai(project_id, cred_file):
    # ç¢ºä¿æœ‰å°ˆæ¡ˆ ID å’Œæ†‘è­‰æª”æ¡ˆç‰©ä»¶
    if not project_id or cred_file is None: return None
    try:
        # 1. å‰µé€ ä¸€å€‹æš«æ™‚çš„æª”æ¡ˆä¾†å­˜ json å…§å®¹
        with tempfile.NamedTemporaryFile(delete=False, suffix=".json", mode='w+', encoding='utf-8') as tmp:
            # æŠŠä¸Šå‚³æª”æ¡ˆçš„å…§å®¹å¯«é€²å»
            # cred_file æ˜¯ä¸€å€‹ BytesIO ç‰©ä»¶ï¼Œè¦ decode æˆå­—ä¸²
            content = cred_file.getvalue().decode("utf-8")
            tmp.write(content)
            tmp_cred_path = tmp.name
        
        # 2. å‘Šè¨´ Google SDK æš«æ™‚çš„æ†‘è­‰æª”æ¡ˆåœ¨å“ªè£¡
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = tmp_cred_path
        
        # 3. åˆå§‹åŒ– Vertex AI
        vertexai.init(project=project_id, location="us-central1")
        return True
    except Exception as e:
        print(f"Vertex AI Init Error: {e}")
        return None

# ==========================================
# 1. UI ç¾åŒ–
# ==========================================
def inject_custom_css():
    st.markdown("""
        <style>
        .stApp { background: linear-gradient(135deg, #fdfbf7 0%, #ebedee 100%); font-family: 'Microsoft JhengHei', sans-serif; }
        .reading-box { font-size: 26px !important; font-weight: bold; color: #2c3e50; line-height: 1.6; padding: 20px; background-color: #ffffff; border-left: 8px solid #4285F4; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); margin-bottom: 20px; }
        .definition-card { background-color: #fff9c4; border: 2px solid #fbc02d; color: #5d4037; padding: 15px; border-radius: 12px; margin-top: 15px; font-size: 18px; }
        .mobile-hint-card { background-color: #e3f2fd; border-left: 5px solid #2196f3; padding: 10px; border-radius: 8px; margin-bottom: 10px; font-size: 16px; font-weight: 600; color: #0d47a1; }
        .quiz-box { background-color: #ffffff; border: 2px solid #4caf50; padding: 20px; border-radius: 15px; margin-top: 10px; box-shadow: 0 4px 10px rgba(0,0,0,0.1); }
        .backup-alert { background-color: #e8f5e9; border: 2px solid #66bb6a; padding: 20px; border-radius: 15px; text-align: center; margin-top: 20px; margin-bottom: 20px; }
        div.stButton > button { width: 100%; border-radius: 8px; height: 3em; font-weight: bold; }
        .ai-feedback-box { background-color: #f1f8e9; border-left: 5px solid #8bc34a; padding: 15px; border-radius: 10px; color: #33691e; margin-top: 20px;}
        .diff-box { background-color: #fff; border: 2px dashed #bdc3c7; padding: 15px; border-radius: 10px; font-size: 18px; }
        </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. æ ¸å¿ƒåŠŸèƒ½
# ==========================================
def split_text_into_sentences(text):
    text = text.replace('\n', ' ')
    raw_sentences = re.split(r'(?<=[.!?])\s+', text)
    return [s.strip() for s in raw_sentences if len(s.strip()) > 0]

def transcribe_audio(audio_path):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            audio_data = r.record(source)
            return r.recognize_google(audio_data, language="en-US")
    except: return ""

def check_similarity_visual(target, user_text):
    if not user_text: return 0, "ç„¡èªéŸ³è¼¸å…¥"
    t_words = re.findall(r"\w+", target.lower())
    u_words = re.findall(r"\w+", user_text.lower())
    matcher = difflib.SequenceMatcher(None, t_words, u_words)
    score = matcher.ratio() * 100
    html_parts = []
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        t_segment = " ".join(t_words[i1:i2])
        u_segment = " ".join(u_words[j1:j2])
        if tag == 'equal': html_parts.append(f'<span style="color:green;font-weight:bold;">{t_segment}</span>')
        elif tag == 'replace': html_parts.append(f'<span style="color:red;text-decoration:line-through;">{t_segment}</span> <span style="color:gray;">({u_segment})</span>')
        elif tag == 'delete': html_parts.append(f'<span style="background-color:#ffcccc;color:red;">{t_segment}</span>')
        elif tag == 'insert': html_parts.append(f'<span style="color:gray;font-style:italic;">{u_segment}</span>')
    return score, " ".join(html_parts)

def plot_and_get_trend(teacher_path, student_path):
    if not HAS_LIBROSA: return None, 0, 0
    try:
        y_t, sr_t = librosa.load(teacher_path, sr=22050)
        f0_t, _, _ = librosa.pyin(y_t, fmin=50, fmax=400, frame_length=2048)
        y_s, sr_s = librosa.load(student_path, sr=22050)
        f0_s, _, _ = librosa.pyin(y_s, fmin=50, fmax=400, frame_length=2048)
        if f0_t is None or f0_s is None: return None, 0, 0
        
        def normalize(f0):
            valid = f0[~np.isnan(f0)]
            if len(valid) == 0: return np.array([])
            return (valid - np.mean(valid)) / (np.std(valid) + 1e-6)
        
        norm_t = normalize(f0_t)
        norm_s = normalize(f0_s)
        if len(norm_t) == 0 or len(norm_s) == 0: return None, 0, 0
        
        from scipy.signal import resample
        norm_s_res = resample(norm_s, len(norm_t))
        raw_pitch_score = max(0, np.corrcoef(norm_t, norm_s_res)[0, 1]) * 100
        
        fig, ax = plt.subplots(figsize=(8, 2))
        ax.plot(norm_t, label='Teacher', color='#42a5f5', linewidth=2)
        ax.plot(norm_s_res, label='You', color='#ffa726', linestyle='--', linewidth=2)
        ax.axis('off')
        plt.close(fig)
        return fig, raw_pitch_score, 0
    except: return None, 0, 0

# [ä¿®æ”¹] ä½¿ç”¨ Vertex AI çš„å›é¥‹å‡½å¼ (å‚³å…¥ cred_file)
def get_ai_coach_feedback(project_id, cred_file, target_text, user_text, score):
    if not init_vertex_ai(project_id, cred_file): return "âš ï¸ è«‹æª¢æŸ¥ Project ID ä¸¦ä¸€å®šè¦ä¸Šå‚³æ†‘è­‰ JSON æª”æ¡ˆ"
    try:
        # ä½¿ç”¨æœ€æ–°çš„ Gemini Pro æ¨¡å‹
        model = GenerativeModel("gemini-1.5-pro-preview-0409")
        prompt = f"""
        ä½ æ˜¯ä¸€ä½æº«æš–çš„è‹±æ–‡è€å¸«ã€‚
        ç›®æ¨™å¥å­ï¼š"{target_text}"
        å­¸ç”Ÿå”¸å‡ºï¼š"{user_text}"
        åˆ†æ•¸ï¼š{score:.0f}
        è«‹çµ¦äºˆç¹é«”ä¸­æ–‡å›é¥‹ï¼š
        1. ğŸŒŸ äº®é»è®šè³
        2. ğŸ”§ å…·é«”ç™¼éŸ³ç³¾æ­£ (æŒ‡å‡ºå“ªå€‹å­—å”¸éŒ¯)
        3. ğŸ’ª æš–å¿ƒé¼“å‹µ
        """
        responses = model.generate_content(prompt, stream=False)
        return responses.text
    except Exception as e:
        return f"AI éŒ¯èª¤: {str(e)}"

# [ä¿®æ”¹] ä½¿ç”¨ Vertex AI çš„å–®å­—æŸ¥è©¢å‡½å¼ (å‚³å…¥ cred_fileï¼Œä¸¦åŠ å…¥å¿«å–æ¸…é™¤é‚è¼¯)
def get_word_info(_cred_file, project_id, word, sentence):
    if not init_vertex_ai(project_id, _cred_file): return "âš ï¸ è«‹æª¢æŸ¥ Project ID ä¸¦ä¸€å®šè¦ä¸Šå‚³æ†‘è­‰ JSON æª”æ¡ˆ"
    try:
        # ä½¿ç”¨æœ€æ–°çš„ Gemini Pro æ¨¡å‹
        model = GenerativeModel("gemini-1.5-pro-preview-0409")
        prompt = f"è§£é‡‹å–®å­— '{word}' åœ¨å¥å­ '{sentence}' ä¸­çš„æ„æ€ã€‚æ ¼å¼ï¼šğŸ”Š[{word}] KKéŸ³æ¨™\\nğŸ·ï¸[è©æ€§]\\nğŸ’¡[ç¹ä¸­æ„æ€](ç°¡æ½”)"
        responses = model.generate_content(prompt, stream=False)
        return responses.text
    except Exception as e:
        print(f"Vertex AI Query Failed: {e}")
        return f"âŒ æŸ¥è©¢å¤±æ•—: {str(e)}"

# [ä¿®æ”¹] ä½¿ç”¨ Vertex AI çš„å‡ºé¡Œå‡½å¼ (å‚³å…¥ cred_file)
def generate_quiz(project_id, cred_file, word):
    if not init_vertex_ai(project_id, cred_file): return None
    try:
        model = GenerativeModel("gemini-1.5-pro-preview-0409")
        prompt = f"""
        è«‹é‡å°å–®å­— "{word}" å‡ºä¸€å€‹ã€Œå¥å­å¡«ç©ºé¡Œã€ã€‚
        æ ¼å¼è¦æ±‚ï¼š
        Q: [è‹±æ–‡å¥å­ï¼Œå°‡ {word} æŒ–ç©ºè®Šæˆ ______ ]
        A: [ç¹é«”ä¸­æ–‡ç¿»è­¯]
        """
        responses = model.generate_content(prompt, stream=False)
        return responses.text
    except: return None

# ç™¼éŸ³é‚è¼¯
def speak_google(text, speed=1.0):
    try:
        is_slow = speed < 1.0
        tts = gTTS(text=text, lang='en', slow=is_slow)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
            tts.save(fp.name)
            return fp.name
    except: return None

def speak_offline(text, speed=1.0):
    if not HAS_OFFLINE_TTS: return None
    try:
        engine = pyttsx3.init()
        engine.setProperty('rate', int(175 * speed))
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
            engine.save_to_file(text, fp.name)
            engine.runAndWait()
            return fp.name
    except: return None

def get_offline_voices():
    try:
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        return {v.name: v.id for v in voices}
    except: return {}

# ==========================================
# 3. ä¸»ç¨‹å¼ä»‹é¢
# ==========================================
inject_custom_css()

# Session åˆå§‹åŒ–
if 'game_active' not in st.session_state: st.session_state.game_active = False
if 'sentences' not in st.session_state: st.session_state.sentences = []
if 'current_index' not in st.session_state: st.session_state.current_index = 0
if 'current_word_info' not in st.session_state: st.session_state.current_word_info = None
if 'current_word_target' not in st.session_state: st.session_state.current_word_target = None
if 'current_word_audio' not in st.session_state: st.session_state.current_word_audio = None
if 'current_audio_path' not in st.session_state: st.session_state.current_audio_path = None
if 'quiz_data' not in st.session_state: st.session_state.quiz_data = None
if 'quiz_answer_show' not in st.session_state: st.session_state.quiz_answer_show = False
if 'is_finished' not in st.session_state: st.session_state.is_finished = False

# è®€å– Project ID
if 'saved_project_id' not in st.session_state:
    if os.path.exists(PROJECT_FILE):
        with open(PROJECT_FILE, "r") as f: st.session_state.saved_project_id = f.read().strip()
    else: st.session_state.saved_project_id = ""

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.title("âš™ï¸ è¨­å®š (Vertex æœ¬æ©Ÿç‰ˆ)")
    
    # Project ID è¼¸å…¥æ¡†
    google_project_id = st.text_input("Google Project ID", value=st.session_state.saved_project_id)
    if google_project_id != st.session_state.saved_project_id:
        with open(PROJECT_FILE, "w") as f: f.write(google_project_id)
        st.session_state.saved_project_id = google_project_id

    # [é—œéµ] æ†‘è­‰æª”æ¡ˆä¸Šå‚³ (ä¸€å®šè¦æœ‰é€™å€‹æª”æ¡ˆ)
    st.markdown("### ğŸ” é©—è­‰æ–¹å¼ (å¿…å¡«)")
    st.info("è«‹ä¸Šå‚³æ‚¨çš„ Google Cloud æœå‹™å¸³æˆ¶ JSON æ†‘è­‰æª”ã€‚")
    uploaded_creds = st.file_uploader("ğŸ“„ ä¸Šå‚³ Google æ†‘è­‰ (JSON)", type=["json"], key="vertex_creds")

    if not google_project_id or not uploaded_creds:
        st.error("â›” è«‹è¼¸å…¥ Project ID ä¸¦ä¸Šå‚³æ†‘è­‰æª”æ¡ˆï¼Œå¦å‰‡ç„¡æ³•æŸ¥è©¢ï¼")
    else:
        st.success("âœ… æ†‘è­‰å·²è¼‰å…¥ï¼Œå¯ä»¥é–‹å§‹ä½¿ç”¨ï¼")
    
    st.markdown("---")
    app_mode = st.radio("é¸æ“‡æ¨¡å¼", ["ğŸ“– è·Ÿè®€ç·´ç¿’", "ğŸ“ å–®å­—æ¸¬é©—"], index=0)
    st.markdown("---")
    
    with st.expander("ğŸ’¾ è³‡æ–™å‚™ä»½èˆ‡é‚„åŸ", expanded=True):
        vocab_list = load_vocab()
        if vocab_list:
            json_str = json.dumps(vocab_list, ensure_ascii=False, indent=4)
            st.download_button("ğŸ“¥ ä¸‹è¼‰å–®å­—æœ¬", json_str, "my_vocab.json", "application/json")
        uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šå‚³é‚„åŸ", type=["json"])
        if uploaded_file:
            try:
                data = json.load(uploaded_file)
                save_vocab_to_disk(data)
                st.success("é‚„åŸæˆåŠŸï¼")
            except: pass

    st.markdown("---")
    if HAS_OFFLINE_TTS:
        tts_mode = st.radio("ç™¼éŸ³å¼•æ“", ["â˜ï¸ ç·šä¸Š (Google)", "ğŸ’» é›¢ç·š (Windows)"], index=0)
    else:
        tts_mode = "â˜ï¸ ç·šä¸Š (Google)"
    voice_speed = st.slider("èªé€Ÿ", 0.5, 1.5, 1.0, 0.1)

st.title("ğŸ¤ AI è‹±æ–‡æ•™ç·´ (ä»˜è²»å‡ç´šç‰ˆ)")

# ==========================================
# æ¨¡å¼ A: è·Ÿè®€ç·´ç¿’
# ==========================================
if app_mode == "ğŸ“– è·Ÿè®€ç·´ç¿’":
    if not st.session_state.game_active:
        st.markdown('<div class="reading-box">æ­¡è¿ï¼è«‹è¼¸å…¥æ–‡ç« é–‹å§‹ç·´ç¿’ã€‚</div>', unsafe_allow_html=True)
        input_text = st.text_area("æ–‡ç« å…§å®¹ï¼š", value="Technology is changing how we live and work every single day.", height=150)
        if st.button("ğŸš€ é–‹å§‹ç·´ç¿’", type="primary", use_container_width=True):
            s = split_text_into_sentences(input_text)
            if s: 
                st.session_state.sentences = s
                st.session_state.current_index = 0
                st.session_state.game_active = True
                st.session_state.is_finished = False
                st.rerun()
    else:
        if st.session_state.is_finished:
            st.balloons()
            st.markdown("""
            <div class="backup-alert">
                <h2>ğŸ‰ ç·´ç¿’çµæŸï¼</h2>
                <p>è«‹é»æ“Šä¸‹æ–¹æŒ‰éˆ•ä¸‹è¼‰æ‚¨çš„å–®å­—æœ¬å‚™ä»½ã€‚</p>
            </div>
            """, unsafe_allow_html=True)
            vocab_list = load_vocab()
            if vocab_list:
                json_str = json.dumps(vocab_list, ensure_ascii=False, indent=4)
                st.download_button(
                    label="ğŸ“¥ é»æˆ‘ä¸‹è¼‰å–®å­—æœ¬ (Backup)",
                    data=json_str,
                    file_name="vocab_book_backup.json",
                    mime="application/json",
                    type="primary",
                    use_container_width=True
                )
            else:
                st.info("é€™æ¬¡æ²’æœ‰æ”¶è—æ–°å–®å­—ã€‚")
            if st.button("ğŸ”„ å†ç·´ä¸€æ¬¡ / å›åˆ°é¦–é "):
                st.session_state.game_active = False
                st.session_state.is_finished = False
                st.rerun()
            st.stop()

        idx = st.session_state.current_index
        sentences = st.session_state.sentences
        target_sentence = sentences[idx]

        c1, c2, c3 = st.columns([1, 4, 1])
        with c1: 
            if st.button("â¬…ï¸ ä¸Šå¥", disabled=(idx==0), use_container_width=True):
                st.session_state.current_index -= 1
                st.session_state.current_audio_path = None
                st.rerun()
        with c2: st.progress((idx+1)/len(sentences), text=f"é€²åº¦ï¼š{idx+1} / {len(sentences)}")
        with c3:
            is_last = (idx == len(sentences) - 1)
            btn_text = "å®Œæˆ ğŸ‰" if is_last else "ä¸‹å¥ â¡ï¸"
            if st.button(btn_text, use_container_width=True):
                if is_last:
                    st.session_state.is_finished = True
                    st.rerun()
                else:
                    st.session_state.current_index += 1
                    st.session_state.current_audio_path = None
                    st.rerun()

        if st.button("ğŸ ä¸­é€”çµæŸä¸¦å‚™ä»½", type="secondary", use_container_width=True):
            st.session_state.is_finished = True
            st.rerun()

        col_L, col_R = st.columns([1.5, 1], gap="large")

        with col_L:
            st.subheader("ğŸ“– é–±è®€")
            st.markdown(f'<div class="reading-box">{target_sentence}</div>', unsafe_allow_html=True)
            
            st.caption("ğŸ‘‡ é»æ“ŠæŸ¥å–®å­— (ä½¿ç”¨ Google Vertex AI)ï¼š")
            words = re.findall(r"\b\w+\b", target_sentence)
            cols = st.columns(5)
            for i, word in enumerate(words):
                # [ä¿®æ”¹] åªæœ‰åœ¨æœ‰ä¸Šå‚³æ†‘è­‰æ™‚æ‰å…è¨±é»æ“Š
                if cols[i % 5].button(word, key=f"w_{idx}_{i}", disabled=not uploaded_creds):
                    st.session_state.current_word_target = word
                    with st.spinner("ğŸ” Vertex AI æŸ¥è©¢ä¸­..."):
                        # [ä¿®æ”¹] å‚³å…¥ uploaded_creds
                        info = get_word_info(uploaded_creds, google_project_id, word, target_sentence)
                        st.session_state.current_word_info = info
                        
                        if "æŸ¥è©¢å¤±æ•—" not in info and "è«‹æª¢æŸ¥" not in info:
                            w_path = speak_google(word, 1.0)
                            if not w_path: w_path = speak_offline(word, 1.0)
                            st.session_state.current_word_audio = w_path
                        else:
                            st.session_state.current_word_audio = None
            
            if not uploaded_creds:
                 st.warning("è«‹å…ˆåœ¨å´é‚Šæ¬„ä¸Šå‚³æ†‘è­‰æª”æ¡ˆï¼Œæ‰èƒ½ä½¿ç”¨å–®å­—æŸ¥è©¢åŠŸèƒ½ã€‚")

            if st.session_state.current_word_info:
                info_html = st.session_state.current_word_info.replace('\n', '<br>')
                st.markdown(f'<div class="definition-card">{info_html}</div>', unsafe_allow_html=True)
                
                c_p, c_s = st.columns([4, 1])
                with c_p:
                    if st.session_state.current_word_audio:
                        st.audio(st.session_state.current_word_audio, format='audio/mp3')
                with c_s:
                    if "æŸ¥è©¢å¤±æ•—" not in st.session_state.current_word_info and "è«‹æª¢æŸ¥" not in st.session_state.current_word_info:
                        if st.button("â­ æ”¶è—", use_container_width=True):
                            saved = add_word_to_vocab(st.session_state.current_word_target, st.session_state.current_word_info)
                            if saved: st.toast("âœ… å·²æ”¶è—")
                            else: st.toast("âš ï¸ å·²å­˜åœ¨")

            st.markdown("---")
            st.subheader("ğŸ—£ï¸ ç¤ºç¯„")
            if st.session_state.current_audio_path is None:
                path = None
                if "ç·šä¸Š" in tts_mode: path = speak_google(target_sentence, voice_speed)
                if not path: path = speak_offline(target_sentence, voice_speed)
                st.session_state.current_audio_path = path

            if st.session_state.current_audio_path:
                st.audio(st.session_state.current_audio_path, format="audio/mp3")
            else:
                st.warning("ç„¡æ³•ç”ŸæˆèªéŸ³")

        with col_R:
            st.subheader("ğŸ™ï¸ å£èªª")
            st.markdown(f'<div class="mobile-hint-card">ğŸ“– è·Ÿè®€ï¼š<br>{target_sentence}</div>', unsafe_allow_html=True)
            # [ä¿®æ”¹] åªæœ‰åœ¨æœ‰ä¸Šå‚³æ†‘è­‰æ™‚æ‰å…è¨±éŒ„éŸ³
            user_audio = st.audio_input("éŒ„éŸ³", key=f"rec_{idx}", disabled=not uploaded_creds)
            if not uploaded_creds:
                 st.warning("è«‹å…ˆä¸Šå‚³æ†‘è­‰æª”æ¡ˆï¼Œæ‰èƒ½ä½¿ç”¨å£èªªè©•åˆ†åŠŸèƒ½ã€‚")
            
            if user_audio and st.session_state.current_audio_path and uploaded_creds:
                with st.spinner("ğŸ¤– Vertex AI åˆ†æä¸­..."):
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                        tmp.write(user_audio.read()); user_path = tmp.name
                    
                    u_text = transcribe_audio(user_path)
                    score_text, diff_html = check_similarity_visual(target_sentence, u_text)
                    fig, raw_pitch_score, _ = plot_and_get_trend(st.session_state.current_audio_path, user_path)
                    
                    adj_pitch = max(60, raw_pitch_score)
                    final_score = (score_text * 0.8) + (adj_pitch * 0.2)
                    # [ä¿®æ”¹] å‚³å…¥ uploaded_creds
                    feedback = get_ai_coach_feedback(google_project_id, uploaded_creds, target_sentence, u_text, final_score)

                if final_score >= 80: st.success(f"ğŸ‰ åˆ†æ•¸ï¼š{final_score:.0f}")
                else: st.info(f"ğŸ’ª åˆ†æ•¸ï¼š{final_score:.0f}")
                
                st.write("ğŸ§ å›æ”¾è‡ªå·±ï¼š")
                st.audio(user_path, format="audio/wav")
                st.markdown(f'<div class="ai-feedback-box">{feedback}</div>', unsafe_allow_html=True)
                
                tab1, tab2 = st.tabs(["ğŸ”¤ ç³¾éŒ¯", "ğŸ“ˆ èªèª¿"])
                with tab1: st.markdown(f'<div class="diff-box">{diff_html}</div>', unsafe_allow_html=True)
                with tab2: 
                    if fig: st.pyplot(fig)
                    else: st.info("ç„¡æ³•åˆ†æèªèª¿")

# ==========================================
# æ¨¡å¼ B: å–®å­—æ¸¬é©—
# ==========================================
elif app_mode == "ğŸ“ å–®å­—æ¸¬é©—":
    vocab_list = load_vocab()
    st.subheader("ğŸ“ å–®å­—æœ¬éš¨å ‚è€ƒ")
    
    if not vocab_list:
        st.info("ğŸ“­ ç›®å‰å–®å­—æœ¬æ˜¯ç©ºçš„ã€‚è«‹å…ˆå»ã€Œè·Ÿè®€ç·´ç¿’ã€æŸ¥è©¢å–®å­—ä¸¦æŒ‰ã€Œâ­ æ”¶è—ã€ã€‚")
    else:
        st.write(f"ğŸ“š ç´¯ç©å–®å­—ï¼š**{len(vocab_list)}** å€‹")
        # [ä¿®æ”¹] åªæœ‰åœ¨æœ‰ä¸Šå‚³æ†‘è­‰æ™‚æ‰å…è¨±å‡ºé¡Œ
        if st.button("ğŸ² éš¨æ©Ÿå‡ºä¸€é¡Œ (Vertex AI)", type="primary", use_container_width=True, disabled=not uploaded_creds):
            target = random.choice(vocab_list)
            word = target["word"]
            info = target["info"]

            with st.spinner(f"æ­£åœ¨ç‚º '{word}' å‡ºé¡Œ..."):
                # [ä¿®æ”¹] å‚³å…¥ uploaded_creds
                q_text = generate_quiz(google_project_id, uploaded_creds, word)
                if q_text and "å¤±æ•—" not in q_text:
                    st.session_state.quiz_data = {"word": word, "content": q_text, "original_info": info}
                    st.session_state.quiz_answer_show = False
                else:
                    st.error("å‡ºé¡Œå¤±æ•— (è«‹æª¢æŸ¥ Project ID å’Œæ†‘è­‰æª”æ¡ˆ)")
        
        if not uploaded_creds:
             st.warning("è«‹å…ˆä¸Šå‚³æ†‘è­‰æª”æ¡ˆï¼Œæ‰èƒ½ä½¿ç”¨æ¸¬é©—åŠŸèƒ½ã€‚")

        if st.session_state.quiz_data:
            data = st.session_state.quiz_data
            content = data["content"]
            try:
                q_part = content.split("A:")[0].replace("Q:", "").strip()
            except:
                q_part = content
            st.markdown(f"""
            <div class="quiz-box">
                <h3>â“ å¡«ç©ºé¡Œï¼š</h3>
                <p style="font-size:22px; font-weight:bold; color:#1565c0;">{q_part}</p>
            </div>
            """, unsafe_allow_html=True)
            
            if st.button("ğŸ‘€ çœ‹ç­”æ¡ˆ", use_container_width=True):
                st.session_state.quiz_answer_show = True
            
            if st.session_state.quiz_answer_show:
                st.success(f"âœ… æ­£ç¢ºå–®å­—ï¼š**{data['word']}**")
                try:
                    a_part = content.split("A:")[1].strip() if "A:" in content else "ç„¡ç¿»è­¯"
                except:
                    a_part = "è§£æéŒ¯èª¤"
                st.info(f"ğŸ’¡ ç¿»è­¯ï¼š{a_part}")

                st.markdown("---")
                st.caption("ğŸ“œ åŸå§‹å–®å­—å¡è³‡æ–™ï¼š")
                original_html = data['original_info'].replace('\n', '<br>')
                st.markdown(f'<div style="background-color:#fff9c4; padding:10px; border-radius:8px;">{original_html}</div>', unsafe_allow_html=True)

                w_path = speak_google(data['word'])
                if w_path: st.audio(w_path, format='audio/mp3')