import streamlit as st

# 1. è¨­å®šé é¢ (çµ•å°ç¬¬ä¸€è¡Œ)
try:
    st.set_page_config(page_title="AI è‹±æ–‡æ•™ç·´ Pro (é›™å¹³å°ç‰ˆ)", layout="wide", page_icon="ğŸ¤")
except:
    pass

import speech_recognition as sr
from gtts import gTTS
import tempfile
import os
import difflib
import re
import numpy as np
import matplotlib.pyplot as plt
import google.generativeai as genai
import ssl

# 2. å¿½ç•¥ SSL éŒ¯èª¤
ssl._create_default_https_context = ssl._create_unverified_context

# 3. å®‰å…¨åŒ¯å…¥ (é˜²æ­¢é›²ç«¯å´©æ½°çš„é—œéµï¼)
HAS_OFFLINE_TTS = False
try:
    import pyttsx3
    HAS_OFFLINE_TTS = True
except ImportError:
    HAS_OFFLINE_TTS = False

try:
    import librosa
    HAS_LIBROSA = True
except ImportError:
    HAS_LIBROSA = False

# ==========================================
# 0. UI ç¾åŒ–
# ==========================================
def inject_custom_css():
    st.markdown("""
        <style>
        .stApp { background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%); font-family: 'Microsoft JhengHei', sans-serif; }
        
        .reading-box { 
            font-size: 26px !important; 
            font-weight: bold; 
            color: #2c3e50; 
            line-height: 1.6; 
            padding: 20px; 
            background-color: #ffffff; 
            border-left: 8px solid #4285F4; 
            border-radius: 10px; 
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 25px; 
        }

        .definition-card { 
            background-color: #fff9c4; border: 2px solid #fbc02d; color: #5d4037; 
            padding: 15px; border-radius: 12px; margin-top: 15px; font-size: 18px; 
        }
        
        /* æ‰‹æ©Ÿç‰ˆæç¤ºå¡ */
        .mobile-hint-card {
            background-color: #e3f2fd;
            border: 1px solid #90caf9;
            padding: 12px;
            border-radius: 8px;
            margin-bottom: 10px;
            font-size: 16px;
            font-weight: 600;
            color: #1565c0;
            line-height: 1.4;
        }

        div.stButton > button { width: 100%; border-radius: 8px; height: 3em; font-weight: bold; }
        
        .ai-feedback-box { background-color: #f1f8e9; border-left: 5px solid #8bc34a; padding: 15px; border-radius: 10px; color: #33691e; margin-top: 20px;}
        .diff-box { background-color: #fff; border: 2px dashed #bdc3c7; padding: 15px; border-radius: 10px; font-size: 18px; }
        </style>
    """, unsafe_allow_html=True)

# ==========================================
# 1. æ ¸å¿ƒåŠŸèƒ½
# ==========================================
def split_text_into_sentences(text):
    text = text.replace('\n', ' ')
    raw_sentences = re.split(r'(?<=[.!?])\s+', text)
    # [ä¿®æ­£] è£œé½Šä¸Šæ¬¡æ–·æ‰çš„èªæ³•
    return [s.strip() for s in raw_sentences if len(s.strip()) > 0]

def transcribe_audio(audio_path):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            audio_data = r.record(source)
            return r.recognize_google(audio_data, language="en-US")
    except: return ""

def check_similarity_visual(target, user_text):
    if not user_text: return 0, "ç„¡èªéŸ³è¼¸å…¥"
    t_words = re.findall(r"\w+", target.lower())
    u_words = re.findall(r"\w+", user_text.lower())
    matcher = difflib.SequenceMatcher(None, t_words, u_words)
    score = matcher.ratio() * 100
    html_parts = []
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        t_segment = " ".join(t_words[i1:i2])
        u_segment = " ".join(u_words[j1:j2])
        if tag == 'equal': html_parts.append(f'<span style="color:green;font-weight:bold;">{t_segment}</span>')
        elif tag == 'replace': html_parts.append(f'<span style="color:red;text-decoration:line-through;">{t_segment}</span> <span style="color:gray;">({u_segment})</span>')
        elif tag == 'delete': html_parts.append(f'<span style="background-color:#ffcccc;color:red;">{t_segment}</span>')
        elif tag == 'insert': html_parts.append(f'<span style="color:gray;font-style:italic;">{u_segment}</span>')
    return score, " ".join(html_parts)

def plot_and_get_trend(teacher_path, student_path):
    if not HAS_LIBROSA: return None, 0, 0
    try:
        y_t, sr_t = librosa.load(teacher_path, sr=22050)
        f0_t, _, _ = librosa.pyin(y_t, fmin=50, fmax=400, frame_length=2048)
        y_s, sr_s = librosa.load(student_path, sr=22050)
        f0_s, _, _ = librosa.pyin(y_s, fmin=50, fmax=400, frame_length=2048)
        if f0_t is None or f0_s is None: return None, 0, 0
        
        def normalize(f0):
            valid = f0[~np.isnan(f0)]
            if len(valid) == 0: return np.array([])
            return (valid - np.mean(valid)) / (np.std(valid) + 1e-6)
        
        norm_t = normalize(f0_t)
        norm_s = normalize(f0_s)
        if len(norm_t) == 0 or len(norm_s) == 0: return None, 0, 0
        
        from scipy.signal import resample
        norm_s_res = resample(norm_s, len(norm_t))
        raw_pitch_score = max(0, np.corrcoef(norm_t, norm_s_res)[0, 1]) * 100
        
        fig, ax = plt.subplots(figsize=(8, 2))
        ax.plot(norm_t, label='Teacher', color='#42a5f5', linewidth=2)
        ax.plot(norm_s_res, label='You', color='#ffa726', linestyle='--', linewidth=2)
        ax.axis('off')
        plt.close(fig)
        
        return fig, raw_pitch_score, 0
    except: return None, 0, 0

def get_ai_coach_feedback(api_key, target_text, user_text, score):
    if not api_key: return "âš ï¸ è«‹è¼¸å…¥ API Key"
    try:
        genai.configure(api_key=api_key)
        # [é–å®š] Gemini 2.0 Flash (ä¸åŠ  exp)
        model = genai.GenerativeModel('gemini-2.0-flash')
        prompt = f"""
        ä½ æ˜¯ä¸€ä½æº«æš–çš„è‹±æ–‡è€å¸«ã€‚
        ç›®æ¨™å¥å­ï¼š"{target_text}"
        å­¸ç”Ÿå”¸å‡ºï¼š"{user_text}"
        è«‹çµ¦äºˆç¹é«”ä¸­æ–‡å›é¥‹ï¼š
        1. ğŸŒŸ äº®é»è®šè³ (å”¸å¾—å¥½çš„åœ°æ–¹)
        2. ğŸ”§ å…·é«”ç™¼éŸ³ç³¾æ­£ (æŒ‡å‡ºå“ªå€‹å­—å”¸éŒ¯)
        3. ğŸ’ª æš–å¿ƒé¼“å‹µ
        (èªæ°£è¦ªåˆ‡ï¼Œä¸è¦æ‰¹è©•)
        """
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        if "429" in str(e): return "â³ AI ä¼‘æ¯ä¸­ (429)ï¼Œè«‹ç¨å€™ã€‚"
        return f"AI éŒ¯èª¤: {str(e)}"

@st.cache_data(show_spinner=False)
def get_word_info(api_key, word, sentence):
    if not api_key: return "âš ï¸ è«‹è¼¸å…¥ Key"
    try:
        genai.configure(api_key=api_key)
        # [é–å®š] Gemini 2.0 Flash
        model = genai.GenerativeModel('gemini-2.0-flash')
        prompt = f"è§£é‡‹å–®å­— '{word}' åœ¨å¥å­ '{sentence}' ä¸­çš„æ„æ€ã€‚æ ¼å¼ï¼šğŸ”Š[{word}] KKéŸ³æ¨™\\nğŸ·ï¸[è©æ€§]\\nğŸ’¡[ç¹ä¸­æ„æ€](ç°¡æ½”)"
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        if "429" in str(e): return "â³ æŸ¥è©¢å¤ªå¿« (429)"
        return "âŒ æŸ¥è©¢å¤±æ•—"

# ç™¼éŸ³é‚è¼¯
def speak_google(text, speed=1.0):
    try:
        is_slow = speed < 1.0
        tts = gTTS(text=text, lang='en', slow=is_slow)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
            tts.save(fp.name)
            return fp.name
    except: return None

def speak_offline(text, speed=1.0):
    # [ä¿®æ­£] é€™è£¡åŠ ä¸Šäº†æª¢æŸ¥ï¼Œå¦‚æœæ²’å®‰è£ (é›²ç«¯ç’°å¢ƒ)ï¼Œç›´æ¥å›å‚³ Noneï¼Œé˜²æ­¢å´©æ½°
    if not HAS_OFFLINE_TTS: return None
    try:
        engine = pyttsx3.init()
        engine.setProperty('rate', int(175 * speed))
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as fp:
            engine.save_to_file(text, fp.name)
            engine.runAndWait()
            return fp.name
    except: return None

def get_offline_voices():
    if not HAS_OFFLINE_TTS: return {}
    try:
        engine = pyttsx3.init()
        voices = engine.getProperty('voices')
        return {v.name: v.id for v in voices}
    except: return {}

# ==========================================
# 2. ä¸»ç¨‹å¼
# ==========================================
inject_custom_css()

# [é—œéµä¿®æ­£] Session åˆå§‹åŒ– (è£œé½Šè®Šæ•¸ï¼Œé˜²æ­¢ AttributeError)
if 'game_active' not in st.session_state: st.session_state.game_active = False
if 'sentences' not in st.session_state: st.session_state.sentences = []
if 'current_index' not in st.session_state: st.session_state.current_index = 0
if 'current_audio_path' not in st.session_state: st.session_state.current_audio_path = None
# ä¸‹é¢é€™ä¸‰å€‹æ˜¯æ‚¨æˆªåœ–å ±éŒ¯ç¼ºå°‘çš„è®Šæ•¸ï¼Œç¾åœ¨è£œä¸Šäº†
if 'current_word_data' not in st.session_state: st.session_state.current_word_data = None 
if 'current_word_info' not in st.session_state: st.session_state.current_word_info = None
if 'current_word_audio' not in st.session_state: st.session_state.current_word_audio = None
if 'current_word_target' not in st.session_state: st.session_state.current_word_target = None

# Key ç®¡ç†
KEY_FILE = "secret_key.txt"
if 'saved_api_key' not in st.session_state:
    if os.path.exists(KEY_FILE):
        with open(KEY_FILE, "r") as f: st.session_state.saved_api_key = f.read().strip()
    else: st.session_state.saved_api_key = ""

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    gemini_api_key = st.text_input("Google API Key", value=st.session_state.saved_api_key, type="password")
    if gemini_api_key != st.session_state.saved_api_key:
        with open(KEY_FILE, "w") as f: f.write(gemini_api_key)
        st.session_state.saved_api_key = gemini_api_key
    
    st.markdown("---")
    
    # æ ¹æ“šç’°å¢ƒé¡¯ç¤ºæ¨¡å¼ (é›²ç«¯åªæœƒé¡¯ç¤ºç·šä¸Š)
    if HAS_OFFLINE_TTS:
        tts_mode = st.radio("ç™¼éŸ³æ¨¡å¼", ["â˜ï¸ ç·šä¸Š (Google)", "ğŸ’» é›¢ç·š (Windows)"], index=0)
    else:
        st.info("â˜ï¸ é›²ç«¯æ¨¡å¼ (Google ç™¼éŸ³)")
        tts_mode = "â˜ï¸ ç·šä¸Š (Google)"
        
    voice_speed = st.slider("èªé€Ÿ", 0.5, 1.5, 1.0, 0.1)

# --- ä¸»ç•«é¢ ---
st.title("ğŸ¤ AI è‹±æ–‡æ•™ç·´")

if not st.session_state.game_active:
    st.markdown('<div class="css-card">', unsafe_allow_html=True)
    input_text = st.text_area("è«‹è¼¸å…¥æ–‡ç« ï¼š", value="Technology is changing how we live and work every single day.", height=150)
    if st.button("ğŸš€ é–‹å§‹ç·´ç¿’", type="primary", use_container_width=True):
        s = split_text_into_sentences(input_text)
        if s: 
            st.session_state.sentences = s
            st.session_state.current_index = 0
            st.session_state.game_active = True
            st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)
else:
    # å°èˆªèˆ‡é€²åº¦
    idx = st.session_state.current_index
    sentences = st.session_state.sentences
    target_sentence = sentences[idx]

    c1, c2, c3 = st.columns([1, 2, 1])
    with c1: 
        if st.button("â¬…ï¸ ä¸Šä¸€å¥", disabled=(idx==0), use_container_width=True):
            st.session_state.current_index -= 1
            st.session_state.current_audio_path = None
            st.session_state.current_word_data = None
            st.session_state.current_word_info = None
            st.session_state.current_word_audio = None
            st.rerun()
    with c2: st.progress((idx+1)/len(sentences), text=f"{idx+1}/{len(sentences)}")
    with c3:
        if st.button("ä¸‹ä¸€å¥ â¡ï¸", disabled=(idx==len(sentences)-1), use_container_width=True):
            st.session_state.current_index += 1
            st.session_state.current_audio_path = None
            st.session_state.current_word_data = None
            st.session_state.current_word_info = None
            st.session_state.current_word_audio = None
            st.rerun()

    col_L, col_R = st.columns([1.5, 1], gap="large")

    # === å·¦é‚Šï¼šé–±è®€èˆ‡æŸ¥å–®å­— ===
    with col_L:
        st.subheader("ğŸ“– é–±è®€èˆ‡æŸ¥è©¢")
        st.markdown(f'<div class="reading-box">{target_sentence}</div>', unsafe_allow_html=True)
        
        # å–®å­—æŒ‰éˆ•
        words = re.findall(r"\b\w+\b", target_sentence)
        cols = st.columns(5)
        for i, word in enumerate(words):
            if cols[i % 5].button(word, key=f"w_{idx}_{i}"):
                if gemini_api_key:
                    with st.spinner("ğŸ”..."):
                        # [ä¿®æ­£] ç›´æ¥å‘¼å«å®šç¾©å¥½çš„ get_word_infoï¼Œç§»é™¤éŒ¯èª¤çš„ get_gemini_response
                        info = get_word_info(gemini_api_key, word, target_sentence) 
                        info_html = info.replace('\n', '<br>')
                        
                        # 2. ç™¼éŸ³
                        w_path = speak_google(word, 1.0)
                        if not w_path: w_path = speak_offline(word, 1.0)
                        
                        # [ä¿®æ­£] ç¢ºä¿è®Šæ•¸åç¨±ä¸€è‡´
                        st.session_state.current_word_info = info_html
                        st.session_state.current_word_audio = w_path
                else:
                    st.error("è«‹è¼¸å…¥ Key")

        # é¡¯ç¤ºå–®å­—æŸ¥è©¢çµæœ
        if st.session_state.current_word_info:
            st.markdown(f'<div class="definition-card">{st.session_state.current_word_info}</div>', unsafe_allow_html=True)
            if st.session_state.current_word_audio:
                st.audio(st.session_state.current_word_audio, format='audio/mp3')

        st.markdown("---")
        st.subheader("ğŸ—£ï¸ æ•´å¥ç¤ºç¯„")
        
        # æ•´å¥ç™¼éŸ³
        if st.session_state.current_audio_path is None:
            path = None
            if "ç·šä¸Š" in tts_mode: 
                path = speak_google(target_sentence, voice_speed)
            if not path: 
                path = speak_offline(target_sentence, voice_speed)
            st.session_state.current_audio_path = path

        if st.session_state.current_audio_path:
            st.audio(st.session_state.current_audio_path, format="audio/mp3")
        else:
            st.warning("ç„¡æ³•ç”ŸæˆèªéŸ³")

    # === å³é‚Šï¼šéŒ„éŸ³ ===
    with col_R:
        st.subheader("ğŸ™ï¸ å£èªªæŒ‘æˆ°")
        
        # æ‰‹æ©Ÿç‰ˆè·Ÿè®€æç¤º
        st.markdown(f'<div class="mobile-hint-card">ğŸ“– è·Ÿè®€ï¼š<br>{target_sentence}</div>', unsafe_allow_html=True)
        
        user_audio = st.audio_input("è«‹æŒ‰éŒ„éŸ³éˆ•é–‹å§‹", key=f"rec_{idx}")
        
        if user_audio and st.session_state.current_audio_path:
            with st.spinner("ğŸ¤– åˆ†æä¸­..."):
                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
                    tmp.write(user_audio.read()); user_path = tmp.name
                
                u_text = transcribe_audio(user_path)
                score_text, diff_html = check_similarity_visual(target_sentence, u_text)
                fig, raw_pitch_score, _ = plot_and_get_trend(st.session_state.current_audio_path, user_path)
                
                # é¼“å‹µåˆ¶è©•åˆ†
                adj_pitch = max(60, raw_pitch_score)
                final_score = (score_text * 0.8) + (adj_pitch * 0.2)
                
                feedback = get_ai_coach_feedback(gemini_api_key, target_sentence, u_text, final_score)

            # çµæœé¡¯ç¤º
            if final_score >= 80: st.success(f"ğŸ‰ å¤ªæ£’äº†ï¼åˆ†æ•¸ï¼š{final_score:.0f}")
            else: st.info(f"ğŸ’ª å†è©¦è©¦ï¼š{final_score:.0f}")
            
            # å›æ”¾è‡ªå·±
            st.write("ğŸ§ **å›æ”¾ä½ çš„è²éŸ³ï¼š**")
            st.audio(user_path, format="audio/wav")
            
            st.markdown(f'<div class="ai-feedback-box">{feedback}</div>', unsafe_allow_html=True)
            
            tab1, tab2 = st.tabs(["ğŸ”¤ ç³¾éŒ¯", "ğŸ“ˆ èªèª¿"])
            with tab1: st.markdown(f'<div class="diff-box">{diff_html}</div>', unsafe_allow_html=True)
            with tab2: 
                if fig: st.pyplot(fig)
                else: st.info("ç„¡æ³•åˆ†æèªèª¿")